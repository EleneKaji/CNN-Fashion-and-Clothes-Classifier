{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split # loads data either in chunks or full\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets # open datasets\n",
    "from torchvision.transforms import ToTensor # transfor data to tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='./data/', train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.MNIST(root='./data/', train=False, download=True, transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_size = int(len(train_data) * 0.8)  # 80% of the data for training\n",
    "val_size = len(train_data) - train_size  # 20% of the data for validation\n",
    "train_subset, val_subset = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_subset, batch_size=batch_size) \n",
    "val_dataloader = DataLoader(val_subset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 4, Number: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ70lEQVR4nO3df0yV5/3/8ddR8YgWzmIUzkGRUKPbUoyJP4pi649mEslmanWL1aXBf0ydPxJGTVNrFumWSeNS0z+odms2qlmdLplaE00rqwI2lo0auxrbGRqxsClhEj0H0WKs1/cP4vl+TsEf9/Ec3xx4PpIr8dznfnO/vXuVlxfnnAufc84JAAADQ6wbAAAMXoQQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzAyzbuC7bt++rYsXLyojI0M+n8+6HQCAR845dXZ2KicnR0OG3Hut0+9C6OLFi8rNzbVuAwDwkFpbWzV+/Ph7ntPvfhyXkZFh3QIAIAEe5Pt50kJox44dys/P14gRIzR9+nSdOHHiger4ERwADAwP8v08KSG0b98+lZWVafPmzTp9+rSefvpplZSUqKWlJRmXAwCkKF8ydtEuLCzUtGnTtHPnzuixH/7wh1qyZIkqKyvvWRuJRBQIBBLdEgDgEQuHw8rMzLznOQlfCd28eVOnTp1ScXFxzPHi4mKdPHmy1/nd3d2KRCIxAwAwOCQ8hC5fvqxvv/1W2dnZMcezs7PV1tbW6/zKykoFAoHo4J1xADB4JO2NCd99Qco51+eLVJs2bVI4HI6O1tbWZLUEAOhnEv45oTFjxmjo0KG9Vj3t7e29VkeS5Pf75ff7E90GACAFJHwlNHz4cE2fPl01NTUxx2tqalRUVJToywEAUlhSdkwoLy/XCy+8oBkzZmj27Nn6wx/+oJaWFq1ZsyYZlwMApKikhNDy5cvV0dGhX//617p06ZIKCgp05MgR5eXlJeNyAIAUlZTPCT0MPicEAAODyeeEAAB4UIQQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMDLNuAAD6q+9///uea44cOeK55rXXXvNcs3v3bs81/RErIQCAGUIIAGAm4SFUUVEhn88XM4LBYKIvAwAYAJLymtATTzyhv//979HHQ4cOTcZlAAApLikhNGzYMFY/AID7SsprQk1NTcrJyVF+fr6ef/55nT9//q7ndnd3KxKJxAwAwOCQ8BAqLCzU7t279eGHH+qdd95RW1ubioqK1NHR0ef5lZWVCgQC0ZGbm5volgAA/VTCQ6ikpETLli3TlClT9KMf/UiHDx+WJO3atavP8zdt2qRwOBwdra2tiW4JANBPJf3DqqNGjdKUKVPU1NTU5/N+v19+vz/ZbQAA+qGkf06ou7tbX375pUKhULIvBQBIMQkPoY0bN6qurk7Nzc36xz/+oZ/+9KeKRCIqLS1N9KUAACku4T+O+89//qMVK1bo8uXLGjt2rGbNmqWGhgbl5eUl+lIAgBSX8BDau3dvor8k4Fm8H5COZ8PKL774Iq5rof+bNm2a55px48Z5rgmHw55rBgr2jgMAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGAm6b/UDrAwceLEuOoOHjzouWbOnDmea/73v/95rkH85s6dG1fdjh07PNc0NjZ6rnn//fc91wwUrIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGbYRRv93ogRIzzXlJeXx3Wt4cOHe64ZN26c5xp20Y7f448/7rnm1VdfjetaPp/Pc83bb78d17UGK1ZCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzLCBKfq9V155xXPNihUr4rrWP//5T881//rXv+K6FuKzZs0azzXFxcVxXev3v/+955qDBw/Gda3BipUQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM2xgikdqwYIFnmt++ctfeq7x+/2ea+K9lnMurmtBKi0t9Vzz85//3HNNW1ub5xpJeuuttzzXdHV1xXWtwYqVEADADCEEADDjOYTq6+u1ePFi5eTkyOfz9frdGc45VVRUKCcnR+np6Zo/f77Onj2bqH4BAAOI5xDq6urS1KlTVVVV1efz27Zt0/bt21VVVaXGxkYFg0EtXLhQnZ2dD90sAGBg8fzGhJKSEpWUlPT5nHNOb775pjZv3qylS5dKknbt2qXs7Gzt2bNHL7744sN1CwAYUBL6mlBzc7Pa2tpifpWu3+/XvHnzdPLkyT5ruru7FYlEYgYAYHBIaAjdeRtkdnZ2zPHs7Oy7vkWysrJSgUAgOnJzcxPZEgCgH0vKu+N8Pl/MY+dcr2N3bNq0SeFwODpaW1uT0RIAoB9K6IdVg8GgpJ4VUSgUih5vb2/vtTq6w+/3x/3BQgBAakvoSig/P1/BYFA1NTXRYzdv3lRdXZ2KiooSeSkAwADgeSV07do1ffXVV9HHzc3N+uyzzzR69GhNmDBBZWVl2rp1qyZNmqRJkyZp69atGjlypFauXJnQxgEAqc9zCH366acx+3+Vl5dL6tkD6t1339XLL7+sGzduaO3atbpy5YoKCwt19OhRZWRkJK5rAMCA4HP9bPfFSCSiQCBg3QYewPz58z3XHDp0yHPNY4895rnm6NGjnmskadGiRXHVQXr88cc919TV1XmuGTdunOeaZcuWea6RpAMHDsRVhx7hcFiZmZn3PIe94wAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZhL6m1UxuPzmN7/xXBPPjtjd3d2eazZu3Oi5Bv9fXl6e55q9e/d6rolnR+w//elPnmsOHjzouQaPBishAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZnzOOWfdxP8ViUQUCASs2xhU5syZE1ddfX295xqfz+e5Jp4NTOvq6jzXSFJ1dbXnmr/+9a+eax7V/3bjx4+Pqy6eDT+nTZvmueajjz7yXPOzn/3Mc83Vq1c91+DhhcNhZWZm3vMcVkIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMsIEpVFpaGlfdu+++67mmn023hGhpabFu4a7ut3nk3Xzve9/zXHP79m3PNQUFBZ5r/v3vf3uugQ02MAUA9GuEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMDLNuAKlrIG5GGo8JEyZYt9AvrF271nMNm5GClRAAwAwhBAAw4zmE6uvrtXjxYuXk5Mjn8+ngwYMxz69atUo+ny9mzJo1K1H9AgAGEM8h1NXVpalTp6qqququ5yxatEiXLl2KjiNHjjxUkwCAgcnzGxNKSkpUUlJyz3P8fr+CwWDcTQEABoekvCZUW1urrKwsTZ48WatXr1Z7e/tdz+3u7lYkEokZAIDBIeEhVFJSovfee0/Hjh3TG2+8ocbGRj3zzDPq7u7u8/zKykoFAoHoyM3NTXRLAIB+KuGfE1q+fHn0zwUFBZoxY4by8vJ0+PBhLV26tNf5mzZtUnl5efRxJBIhiABgkEj6h1VDoZDy8vLU1NTU5/N+v19+vz/ZbQAA+qGkf06oo6NDra2tCoVCyb4UACDFeF4JXbt2TV999VX0cXNzsz777DONHj1ao0ePVkVFhZYtW6ZQKKQLFy7o1Vdf1ZgxY/Tcc88ltHEAQOrzHEKffvqpFixYEH185/Wc0tJS7dy5U2fOnNHu3bt19epVhUIhLViwQPv27VNGRkbiugYADAg+1892oYxEIgoEAtZtDCrx3u/Nmzd7rklPT4/rWl5NnDgxrrrCwsIEd9K3kSNHeq55lK+d/ve///VcM2XKFM81V69e9VyD1BEOh5WZmXnPc9g7DgBghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghl20gYc0YcIEzzUfffSR55p4dgb/5JNPPNdI0o9//GPPNeyIje9iF20AQL9GCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADAzDDrBoD+ZNasWZ5rPv74Y881Q4Z4//dfJBLxXLNy5UrPNRKbkeLRYSUEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADBuYYkAaOnRoXHW/+93vPNfEsxlpPDZu3Oi55uuvv05CJ0DisBICAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghg1MMSBt27Ytrro5c+YkuJO+/fa3v/VcU11dnYROAFushAAAZgghAIAZTyFUWVmpmTNnKiMjQ1lZWVqyZInOnTsXc45zThUVFcrJyVF6errmz5+vs2fPJrRpAMDA4CmE6urqtG7dOjU0NKimpka3bt1ScXGxurq6ouds27ZN27dvV1VVlRobGxUMBrVw4UJ1dnYmvHkAQGrz9MaEDz74IOZxdXW1srKydOrUKc2dO1fOOb355pvavHmzli5dKknatWuXsrOztWfPHr344ouJ6xwAkPIe6jWhcDgsSRo9erQkqbm5WW1tbSouLo6e4/f7NW/ePJ08ebLPr9Hd3a1IJBIzAACDQ9wh5JxTeXm5nnrqKRUUFEiS2traJEnZ2dkx52ZnZ0ef+67KykoFAoHoyM3NjbclAECKiTuE1q9fr88//1x/+ctfej3n8/liHjvneh27Y9OmTQqHw9HR2toab0sAgBQT14dVN2zYoEOHDqm+vl7jx4+PHg8Gg5J6VkShUCh6vL29vdfq6A6/3y+/3x9PGwCAFOdpJeSc0/r167V//34dO3ZM+fn5Mc/n5+crGAyqpqYmeuzmzZuqq6tTUVFRYjoGAAwYnlZC69at0549e/T+++8rIyMj+jpPIBBQenq6fD6fysrKtHXrVk2aNEmTJk3S1q1bNXLkSK1cuTIpfwEAQOryFEI7d+6UJM2fPz/meHV1tVatWiVJevnll3Xjxg2tXbtWV65cUWFhoY4ePaqMjIyENAwAGDh8zjln3cT/FYlEFAgErNtAP1JWVua5Jp4NQiUpPT3dc83+/fs917zwwguea27cuOG5BrAUDoeVmZl5z3PYOw4AYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYCau36wKxGvYMO9TrrS01HNNPLthS1JDQ4PnmjVr1niuYUdsoAcrIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGbYwBSPVFpamucav9/vuaazs9NzjSQVFRXFVQcgPqyEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmGEDUzxSN27c8Fxz7do1zzUbNmzwXAPg0WMlBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwbmKLfe/LJJ61bAJAkrIQAAGYIIQCAGU8hVFlZqZkzZyojI0NZWVlasmSJzp07F3POqlWr5PP5YsasWbMS2jQAYGDwFEJ1dXVat26dGhoaVFNTo1u3bqm4uFhdXV0x5y1atEiXLl2KjiNHjiS0aQDAwODpjQkffPBBzOPq6mplZWXp1KlTmjt3bvS43+9XMBhMTIcAgAHroV4TCofDkqTRo0fHHK+trVVWVpYmT56s1atXq729/a5fo7u7W5FIJGYAAAYHn3POxVPonNOzzz6rK1eu6MSJE9Hj+/bt02OPPaa8vDw1NzfrV7/6lW7duqVTp07J7/f3+joVFRV67bXX4v8bAAD6pXA4rMzMzHuf5OK0du1al5eX51pbW+953sWLF11aWpr729/+1ufz33zzjQuHw9HR2trqJDEYDAYjxUc4HL5vlsT1YdUNGzbo0KFDqq+v1/jx4+95bigUUl5enpqamvp83u/397lCAgAMfJ5CyDmnDRs26MCBA6qtrVV+fv59azo6OtTa2qpQKBR3kwCAgcnTGxPWrVunP//5z9qzZ48yMjLU1tamtrY23bhxQ5J07do1bdy4UZ988okuXLig2tpaLV68WGPGjNFzzz2XlL8AACCFeXkdSHf5uV91dbVzzrnr16+74uJiN3bsWJeWluYmTJjgSktLXUtLywNfIxwOm/8ck8FgMBgPPx7kNaG43x2XLJFIRIFAwLoNAMBDepB3x7F3HADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADATL8LIeecdQsAgAR4kO/n/S6EOjs7rVsAACTAg3w/97l+tvS4ffu2Ll68qIyMDPl8vpjnIpGIcnNz1draqszMTKMO7XEfenAfenAfenAfevSH++CcU2dnp3JycjRkyL3XOsMeUU8PbMiQIRo/fvw9z8nMzBzUk+wO7kMP7kMP7kMP7kMP6/sQCAQe6Lx+9+M4AMDgQQgBAMykVAj5/X5t2bJFfr/fuhVT3Ice3Ice3Ice3IceqXYf+t0bEwAAg0dKrYQAAAMLIQQAMEMIAQDMEEIAADMpFUI7duxQfn6+RowYoenTp+vEiRPWLT1SFRUV8vl8MSMYDFq3lXT19fVavHixcnJy5PP5dPDgwZjnnXOqqKhQTk6O0tPTNX/+fJ09e9am2SS6331YtWpVr/kxa9Ysm2aTpLKyUjNnzlRGRoaysrK0ZMkSnTt3LuacwTAfHuQ+pMp8SJkQ2rdvn8rKyrR582adPn1aTz/9tEpKStTS0mLd2iP1xBNP6NKlS9Fx5swZ65aSrqurS1OnTlVVVVWfz2/btk3bt29XVVWVGhsbFQwGtXDhwgG3D+H97oMkLVq0KGZ+HDly5BF2mHx1dXVat26dGhoaVFNTo1u3bqm4uFhdXV3RcwbDfHiQ+yClyHxwKeLJJ590a9asiTn2gx/8wL3yyitGHT16W7ZscVOnTrVuw5Qkd+DAgejj27dvu2Aw6F5//fXosW+++cYFAgH39ttvG3T4aHz3PjjnXGlpqXv22WdN+rHS3t7uJLm6ujrn3OCdD9+9D86lznxIiZXQzZs3derUKRUXF8ccLy4u1smTJ426stHU1KScnBzl5+fr+eef1/nz561bMtXc3Ky2traYueH3+zVv3rxBNzckqba2VllZWZo8ebJWr16t9vZ265aSKhwOS5JGjx4tafDOh+/ehztSYT6kRAhdvnxZ3377rbKzs2OOZ2dnq62tzairR6+wsFC7d+/Whx9+qHfeeUdtbW0qKipSR0eHdWtm7vz3H+xzQ5JKSkr03nvv6dixY3rjjTfU2NioZ555Rt3d3datJYVzTuXl5XrqqadUUFAgaXDOh77ug5Q686Hf7aJ9L9/91Q7OuV7HBrKSkpLon6dMmaLZs2dr4sSJ2rVrl8rLyw07szfY54YkLV++PPrngoICzZgxQ3l5eTp8+LCWLl1q2FlyrF+/Xp9//rk+/vjjXs8Npvlwt/uQKvMhJVZCY8aM0dChQ3v9S6a9vb3Xv3gGk1GjRmnKlClqamqybsXMnXcHMjd6C4VCysvLG5DzY8OGDTp06JCOHz8e86tfBtt8uNt96Et/nQ8pEULDhw/X9OnTVVNTE3O8pqZGRUVFRl3Z6+7u1pdffqlQKGTdipn8/HwFg8GYuXHz5k3V1dUN6rkhSR0dHWptbR1Q88M5p/Xr12v//v06duyY8vPzY54fLPPhfvehL/12Phi+KcKTvXv3urS0NPfHP/7RffHFF66srMyNGjXKXbhwwbq1R+all15ytbW17vz5866hocH95Cc/cRkZGQP+HnR2drrTp0+706dPO0lu+/bt7vTp0+7rr792zjn3+uuvu0Ag4Pbv3+/OnDnjVqxY4UKhkItEIsadJ9a97kNnZ6d76aWX3MmTJ11zc7M7fvy4mz17ths3btyAug+/+MUvXCAQcLW1te7SpUvRcf369eg5g2E+3O8+pNJ8SJkQcs65t956y+Xl5bnhw4e7adOmxbwdcTBYvny5C4VCLi0tzeXk5LilS5e6s2fPWreVdMePH3eSeo3S0lLnXM/bcrds2eKCwaDz+/1u7ty57syZM7ZNJ8G97sP169ddcXGxGzt2rEtLS3MTJkxwpaWlrqWlxbrthOrr7y/JVVdXR88ZDPPhfvchleYDv8oBAGAmJV4TAgAMTIQQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMz8Pxaq2juGp9SJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "idx = torch.randint(0, 64, (1,)).item()\n",
    "image = images[idx].squeeze()\n",
    "label = labels[idx]\n",
    "print(f\"Name: {label.item()}, Number: {label.item()}\")\n",
    "plt.imshow(image, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, parameters, lr, name):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "        self.name = name\n",
    "\n",
    "        self.momentum = 0.9\n",
    "        self.velocities = [torch.zeros_like(p) for p in parameters]\n",
    "\n",
    "        self.decay_rate = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.sq_grads = [torch.zeros_like(p) for p in parameters]\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.m_t = [torch.zeros_like(p) for p in parameters]\n",
    "        self.v_t = [torch.zeros_like(p) for p in parameters]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        if self.name == \"stochastic\":\n",
    "            self.stochastic_step()\n",
    "        elif self.name == \"momentum\":\n",
    "            self.momentum_step()\n",
    "        elif self.name == \"RMSprop\":\n",
    "            self.RMSprop_step()\n",
    "        elif self.name == \"Adam\":\n",
    "            self.Adam_step()\n",
    "        else:\n",
    "            print(\"no valid optimizer with such name\")\n",
    "\n",
    "    def stochastic_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                if param is not None:\n",
    "                    param -= param.grad * self.lr\n",
    "                    # param.grad.zero_()\n",
    "\n",
    "    def momentum_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param, velocity in zip(self.parameters, self.velocities):\n",
    "                if param is not None:\n",
    "                    # view momentum as the mass that scales the last velocity a bit but still gives more direction\n",
    "                    # the rest is just the stochatic gradient descent\n",
    "                    velocity.mul_(self.momentum).add_(param.grad, alpha=self.lr)\n",
    "                    param.sub_(velocity)\n",
    "                    # param.grad.zero_()\n",
    "\n",
    "                    # another way\n",
    "                    # higher the momentum closer it pays attention to the upcoming points\n",
    "                    # lower the momentum closer it pays attention to the previous points\n",
    "                    # velocity.mul_(self.momentum).add_(param.grad, alpha=(1 - self.momentum))\n",
    "                    # param.sub_(velocity, alpha=self.lr)\n",
    "                    # param.grad.zero_()\n",
    "    \n",
    "    def RMSprop_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param, sq_grad in zip(self.parameters, self.sq_grads):\n",
    "                if param.grad is not None:\n",
    "                    sq_grad.mul_(self.decay_rate).addcmul_(param.grad, param.grad, value=1 - self.decay_rate)\n",
    "                    sqrt = sq_grad.sqrt().add(self.epsilon)\n",
    "                    adjusted_grad = param.grad / sqrt\n",
    "                    param.sub_(adjusted_grad, alpha=self.lr)\n",
    "\n",
    "    def Adam_step(self):\n",
    "        with torch.no_grad():\n",
    "            self.t += 1\n",
    "            for param, m, v in zip(self.parameters, self.m_t, self.v_t):\n",
    "                if param is not None:\n",
    "                    m.mul_(self.beta1).add_(param.grad, alpha=1 - self.beta1)\n",
    "                    v.mul_(self.beta2).addcmul_(param.grad, param.grad, value=1 - self.beta2)\n",
    "                    m_hat = m / (1 - self.beta1 ** self.t)\n",
    "                    v_hat = v / (1 - self.beta2 ** self.t)\n",
    "                    param.sub_(m_hat / (v_hat.sqrt().add(self.epsilon)), alpha=self.lr)\n",
    "\n",
    "    def zero_grads(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                if param.grad is not None:\n",
    "                    param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, out_channels, in_channels, kernel_size, stride=1, padding=0, processor=\"cuda:0\"):\n",
    "        self.w = torch.randn((out_channels, in_channels, kernel_size[0], kernel_size[1]), device=processor, requires_grad=True)\n",
    "        self.b = torch.randn(out_channels, device=processor, requires_grad=True)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        batch_size, in_channels, in_height, in_width = input.shape\n",
    "        out_channels, _, kernel_height, kernel_width = self.w.shape\n",
    "\n",
    "        out_height = (in_height - kernel_height + 2 * self.padding) // self.stride + 1\n",
    "        out_width = (in_width - kernel_width + 2 * self.padding) // self.stride + 1\n",
    "\n",
    "        unfolded_input = torch.zeros(batch_size, out_height, out_width, in_channels * kernel_height * kernel_width, device=self.processor) # [64, 27, 27, 4]\n",
    "\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                start_i = i * self.stride\n",
    "                end_i = start_i + kernel_height\n",
    "                start_j = j * self.stride\n",
    "                end_j = start_j + kernel_width\n",
    "\n",
    "                patch = input[:, :, start_i:end_i, start_j:end_j]\n",
    "                patch = patch.reshape(batch_size, -1)\n",
    "                \n",
    "                unfolded_input[:, i, j, :] = patch\n",
    "        \n",
    "        unfolded_input = unfolded_input.view(batch_size * out_height * out_width, in_channels * kernel_height * kernel_width)\n",
    "        unfolded_kernel = self.w.view(out_channels, -1).t()\n",
    "        \n",
    "        unfolded_output = torch.matmul(unfolded_input, unfolded_kernel)  # [64 * 27 * 27, 12]\n",
    "        output = unfolded_output.view(batch_size, out_height, out_width, out_channels)  # [64, 27, 27, 12]\n",
    "        output = output.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        output += self.b.view(1, out_channels, 1, 1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, w_size, processor=\"cuda:0\"):\n",
    "        self.w_size = w_size\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, input):\n",
    "        batch_size, in_channels, in_height, in_width = input.shape\n",
    "        kernel_height, kernel_width = self.w_size\n",
    "\n",
    "        out_height = in_height // kernel_height\n",
    "        out_width = in_width // kernel_width\n",
    "\n",
    "        output = torch.zeros(batch_size, in_channels, out_height, out_width, device=self.processor) # [64, 27, 27, 4]\n",
    "\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                start_i = i * kernel_height\n",
    "                end_i = start_i + kernel_height\n",
    "                start_j = j * kernel_width\n",
    "                end_j = start_j + kernel_width\n",
    "\n",
    "                window = input[:, :, start_i:end_i, start_j:end_j]\n",
    "                max_values_height, _ = window.max(dim=2, keepdim=True)  # Compute max along height dimension\n",
    "                max_values, _ = max_values_height.max(dim=3, keepdim=True)  # Compute max along width dimension\n",
    "                output[:, :, i, j] = max_values.squeeze() # do not first dim as 1\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: \n",
    "    # nin is the number of input (prev layer)\n",
    "    # nout is the number of output (next layer)\n",
    "    def __init__(self, nin, nout, processor):\n",
    "        self.w = torch.randn((nin, nout), requires_grad=True, device=processor)\n",
    "        self.b = torch.randn(1, requires_grad=True, device=processor)\n",
    "    \n",
    "    # x is the input in (batch, input)\n",
    "    def __call__(self, x):\n",
    "        eq = torch.matmul(x, self.w) + self.b\n",
    "        out = torch.tanh(eq)\n",
    "        return out # returns (batch, output # of neurons for next layer)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts, processor=\"cuda:0\"):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1], processor) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, *layers, lr, optimizer=\"stochastic\"):\n",
    "        self.layers = layers\n",
    "        self.optimizer = Optimizer(self.parameters(), lr, optimizer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grads(self):\n",
    "        self.optimizer.zero_grads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cnn, loss_fn):\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "        \n",
    "        output = cnn(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        cnn.zero_grads()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        cnn.update_parameters()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Loss: {loss:>7f}\\t [{((batch + 1) * 64):>5d}/{937 * 64}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(cnn, loss_fn):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dataloader:\n",
    "            x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "            output = cnn(x)\n",
    "\n",
    "            loss = loss_fn(output, y)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            tot += y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(cnn):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in test_dataloader:\n",
    "            test_x, test_y = test_x.to(\"cuda:0\"), test_y.to(\"cuda:0\")\n",
    "\n",
    "            output = cnn(test_x)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(test_y.view_as(pred)).sum().item()\n",
    "            tot += test_y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(Conv2d(4, 1, (1, 1)), \n",
    "          MaxPool2d((2, 2)), \n",
    "          MLP(784, [64, 32, 10]), lr=0.004, optimizer=\"Adam\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------------\n",
      "Loss: 2.303927\t [   64/59968]\n",
      "Loss: 2.247971\t [ 6464/59968]\n",
      "Loss: 2.202401\t [12864/59968]\n",
      "Loss: 2.203810\t [19264/59968]\n",
      "Loss: 2.198919\t [25664/59968]\n",
      "Loss: 2.136386\t [32064/59968]\n",
      "Loss: 2.097185\t [38464/59968]\n",
      "Loss: 2.128354\t [44864/59968]\n",
      "Loss: 2.122977 Accuracy: 64.816667\n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------------\n",
      "Loss: 2.076894\t [   64/59968]\n",
      "Loss: 2.072985\t [ 6464/59968]\n",
      "Loss: 2.081472\t [12864/59968]\n",
      "Loss: 2.090505\t [19264/59968]\n",
      "Loss: 2.098557\t [25664/59968]\n",
      "Loss: 2.098795\t [32064/59968]\n",
      "Loss: 2.033694\t [38464/59968]\n",
      "Loss: 2.067120\t [44864/59968]\n",
      "Loss: 2.091766 Accuracy: 73.783333\n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------------\n",
      "Loss: 2.056135\t [   64/59968]\n",
      "Loss: 2.056592\t [ 6464/59968]\n",
      "Loss: 2.063082\t [12864/59968]\n",
      "Loss: 2.051788\t [19264/59968]\n",
      "Loss: 2.063281\t [25664/59968]\n",
      "Loss: 2.049937\t [32064/59968]\n",
      "Loss: 2.025012\t [38464/59968]\n",
      "Loss: 2.042135\t [44864/59968]\n",
      "Loss: 2.072970 Accuracy: 79.875000\n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------------\n",
      "Loss: 2.055873\t [   64/59968]\n",
      "Loss: 2.025980\t [ 6464/59968]\n",
      "Loss: 2.052602\t [12864/59968]\n",
      "Loss: 2.036907\t [19264/59968]\n",
      "Loss: 2.035090\t [25664/59968]\n",
      "Loss: 2.043247\t [32064/59968]\n",
      "Loss: 2.029228\t [38464/59968]\n",
      "Loss: 2.044189\t [44864/59968]\n",
      "Loss: 2.058593 Accuracy: 83.100000\n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------------\n",
      "Loss: 2.051760\t [   64/59968]\n",
      "Loss: 2.023105\t [ 6464/59968]\n",
      "Loss: 2.029212\t [12864/59968]\n",
      "Loss: 2.020364\t [19264/59968]\n",
      "Loss: 2.017879\t [25664/59968]\n",
      "Loss: 2.025189\t [32064/59968]\n",
      "Loss: 2.009542\t [38464/59968]\n",
      "Loss: 2.033184\t [44864/59968]\n",
      "Loss: 2.069260 Accuracy: 85.200000\n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------------\n",
      "Loss: 2.023739\t [   64/59968]\n",
      "Loss: 2.006384\t [ 6464/59968]\n",
      "Loss: 2.019381\t [12864/59968]\n",
      "Loss: 2.014358\t [19264/59968]\n",
      "Loss: 2.011619\t [25664/59968]\n",
      "Loss: 2.021784\t [32064/59968]\n",
      "Loss: 2.003869\t [38464/59968]\n",
      "Loss: 2.020038\t [44864/59968]\n",
      "Loss: 2.028158 Accuracy: 86.658333\n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------------\n",
      "Loss: 2.028358\t [   64/59968]\n",
      "Loss: 2.019004\t [ 6464/59968]\n",
      "Loss: 2.010248\t [12864/59968]\n",
      "Loss: 2.006106\t [19264/59968]\n",
      "Loss: 2.006846\t [25664/59968]\n",
      "Loss: 2.009096\t [32064/59968]\n",
      "Loss: 2.000692\t [38464/59968]\n",
      "Loss: 2.025429\t [44864/59968]\n",
      "Loss: 2.047167 Accuracy: 87.625000\n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------------\n",
      "Loss: 2.024534\t [   64/59968]\n",
      "Loss: 1.999763\t [ 6464/59968]\n",
      "Loss: 2.003327\t [12864/59968]\n",
      "Loss: 1.989365\t [19264/59968]\n",
      "Loss: 2.005150\t [25664/59968]\n",
      "Loss: 2.009413\t [32064/59968]\n",
      "Loss: 1.988068\t [38464/59968]\n",
      "Loss: 2.017612\t [44864/59968]\n",
      "Loss: 2.021290 Accuracy: 89.250000\n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------------\n",
      "Loss: 2.018934\t [   64/59968]\n",
      "Loss: 1.990766\t [ 6464/59968]\n",
      "Loss: 2.006208\t [12864/59968]\n",
      "Loss: 2.000142\t [19264/59968]\n",
      "Loss: 1.997445\t [25664/59968]\n",
      "Loss: 2.001265\t [32064/59968]\n",
      "Loss: 1.988364\t [38464/59968]\n",
      "Loss: 2.010714\t [44864/59968]\n",
      "Loss: 2.017356 Accuracy: 88.483333\n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------------\n",
      "Loss: 2.022624\t [   64/59968]\n",
      "Loss: 1.988618\t [ 6464/59968]\n",
      "Loss: 1.999731\t [12864/59968]\n",
      "Loss: 1.993436\t [19264/59968]\n",
      "Loss: 1.995461\t [25664/59968]\n",
      "Loss: 2.012069\t [32064/59968]\n",
      "Loss: 1.982392\t [38464/59968]\n",
      "Loss: 2.016557\t [44864/59968]\n",
      "Loss: 2.019229 Accuracy: 90.225000\n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------------\n",
      "Loss: 2.015080\t [   64/59968]\n",
      "Loss: 2.005132\t [ 6464/59968]\n",
      "Loss: 2.007370\t [12864/59968]\n",
      "Loss: 1.983119\t [19264/59968]\n",
      "Loss: 1.998264\t [25664/59968]\n",
      "Loss: 2.009385\t [32064/59968]\n",
      "Loss: 1.986163\t [38464/59968]\n",
      "Loss: 2.008827\t [44864/59968]\n",
      "Loss: 2.002980 Accuracy: 90.100000\n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------------\n",
      "Loss: 2.031717\t [   64/59968]\n",
      "Loss: 1.997451\t [ 6464/59968]\n",
      "Loss: 2.013863\t [12864/59968]\n",
      "Loss: 1.990110\t [19264/59968]\n",
      "Loss: 2.004494\t [25664/59968]\n",
      "Loss: 2.010200\t [32064/59968]\n",
      "Loss: 1.982329\t [38464/59968]\n",
      "Loss: 2.001415\t [44864/59968]\n",
      "Loss: 2.013071 Accuracy: 89.808333\n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------------\n",
      "Loss: 2.015069\t [   64/59968]\n",
      "Loss: 1.984939\t [ 6464/59968]\n",
      "Loss: 2.008588\t [12864/59968]\n",
      "Loss: 1.983684\t [19264/59968]\n",
      "Loss: 1.986322\t [25664/59968]\n",
      "Loss: 2.011431\t [32064/59968]\n",
      "Loss: 1.984121\t [38464/59968]\n",
      "Loss: 2.013163\t [44864/59968]\n",
      "Loss: 2.020724 Accuracy: 90.866667\n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------------\n",
      "Loss: 1.995131\t [   64/59968]\n",
      "Loss: 1.998341\t [ 6464/59968]\n",
      "Loss: 1.999024\t [12864/59968]\n",
      "Loss: 1.983914\t [19264/59968]\n",
      "Loss: 1.992769\t [25664/59968]\n",
      "Loss: 2.013440\t [32064/59968]\n",
      "Loss: 1.985127\t [38464/59968]\n",
      "Loss: 1.989196\t [44864/59968]\n",
      "Loss: 2.001714 Accuracy: 91.166667\n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------------\n",
      "Loss: 1.997460\t [   64/59968]\n",
      "Loss: 1.993084\t [ 6464/59968]\n",
      "Loss: 2.002080\t [12864/59968]\n",
      "Loss: 1.987027\t [19264/59968]\n",
      "Loss: 2.000820\t [25664/59968]\n",
      "Loss: 2.007648\t [32064/59968]\n",
      "Loss: 1.987205\t [38464/59968]\n",
      "Loss: 2.001886\t [44864/59968]\n",
      "Loss: 1.993076 Accuracy: 91.333333\n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------------\n",
      "Loss: 2.003456\t [   64/59968]\n",
      "Loss: 1.995352\t [ 6464/59968]\n",
      "Loss: 2.000033\t [12864/59968]\n",
      "Loss: 1.983380\t [19264/59968]\n",
      "Loss: 2.006234\t [25664/59968]\n",
      "Loss: 2.006143\t [32064/59968]\n",
      "Loss: 1.985619\t [38464/59968]\n",
      "Loss: 1.993202\t [44864/59968]\n",
      "Loss: 2.026254 Accuracy: 91.558333\n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------------\n",
      "Loss: 2.003273\t [   64/59968]\n",
      "Loss: 1.985865\t [ 6464/59968]\n",
      "Loss: 1.976580\t [12864/59968]\n",
      "Loss: 1.980672\t [19264/59968]\n",
      "Loss: 1.998568\t [25664/59968]\n",
      "Loss: 2.008030\t [32064/59968]\n",
      "Loss: 1.979030\t [38464/59968]\n",
      "Loss: 2.000062\t [44864/59968]\n",
      "Loss: 2.007338 Accuracy: 91.850000\n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------------\n",
      "Loss: 2.002676\t [   64/59968]\n",
      "Loss: 1.983621\t [ 6464/59968]\n",
      "Loss: 1.996977\t [12864/59968]\n",
      "Loss: 1.976668\t [19264/59968]\n",
      "Loss: 2.002611\t [25664/59968]\n",
      "Loss: 1.996979\t [32064/59968]\n",
      "Loss: 1.980335\t [38464/59968]\n",
      "Loss: 1.986175\t [44864/59968]\n",
      "Loss: 2.002429 Accuracy: 91.641667\n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------------\n",
      "Loss: 2.008013\t [   64/59968]\n",
      "Loss: 1.986608\t [ 6464/59968]\n",
      "Loss: 1.981366\t [12864/59968]\n",
      "Loss: 1.986533\t [19264/59968]\n",
      "Loss: 1.992795\t [25664/59968]\n",
      "Loss: 2.013763\t [32064/59968]\n",
      "Loss: 1.977150\t [38464/59968]\n",
      "Loss: 1.979073\t [44864/59968]\n",
      "Loss: 2.006528 Accuracy: 92.075000\n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------------\n",
      "Loss: 2.012284\t [   64/59968]\n",
      "Loss: 1.988659\t [ 6464/59968]\n",
      "Loss: 1.995773\t [12864/59968]\n",
      "Loss: 1.985977\t [19264/59968]\n",
      "Loss: 1.995857\t [25664/59968]\n",
      "Loss: 1.994748\t [32064/59968]\n",
      "Loss: 1.982308\t [38464/59968]\n",
      "Loss: 1.988435\t [44864/59968]\n",
      "Loss: 2.013684 Accuracy: 92.183333\n",
      "\n",
      "Epoch 21\n",
      "-----------------------------------------\n",
      "Loss: 1.994190\t [   64/59968]\n",
      "Loss: 1.989841\t [ 6464/59968]\n",
      "Loss: 1.995874\t [12864/59968]\n",
      "Loss: 1.975452\t [19264/59968]\n",
      "Loss: 2.002065\t [25664/59968]\n",
      "Loss: 2.004350\t [32064/59968]\n",
      "Loss: 1.975613\t [38464/59968]\n",
      "Loss: 1.982951\t [44864/59968]\n",
      "Loss: 2.000563 Accuracy: 92.266667\n",
      "\n",
      "Epoch 22\n",
      "-----------------------------------------\n",
      "Loss: 1.985346\t [   64/59968]\n",
      "Loss: 1.978702\t [ 6464/59968]\n",
      "Loss: 1.982319\t [12864/59968]\n",
      "Loss: 1.974319\t [19264/59968]\n",
      "Loss: 1.987676\t [25664/59968]\n",
      "Loss: 1.997677\t [32064/59968]\n",
      "Loss: 1.975314\t [38464/59968]\n",
      "Loss: 1.986755\t [44864/59968]\n",
      "Loss: 2.014424 Accuracy: 92.775000\n",
      "\n",
      "Epoch 23\n",
      "-----------------------------------------\n",
      "Loss: 1.989966\t [   64/59968]\n",
      "Loss: 1.982656\t [ 6464/59968]\n",
      "Loss: 1.983662\t [12864/59968]\n",
      "Loss: 1.983911\t [19264/59968]\n",
      "Loss: 1.994270\t [25664/59968]\n",
      "Loss: 1.990034\t [32064/59968]\n",
      "Loss: 1.984286\t [38464/59968]\n",
      "Loss: 1.981552\t [44864/59968]\n",
      "Loss: 1.996722 Accuracy: 93.000000\n",
      "\n",
      "Epoch 24\n",
      "-----------------------------------------\n",
      "Loss: 1.988597\t [   64/59968]\n",
      "Loss: 1.983072\t [ 6464/59968]\n",
      "Loss: 1.982549\t [12864/59968]\n",
      "Loss: 1.978339\t [19264/59968]\n",
      "Loss: 1.987478\t [25664/59968]\n",
      "Loss: 2.001355\t [32064/59968]\n",
      "Loss: 1.970360\t [38464/59968]\n",
      "Loss: 1.976276\t [44864/59968]\n",
      "Loss: 1.994160 Accuracy: 92.875000\n",
      "\n",
      "Epoch 25\n",
      "-----------------------------------------\n",
      "Loss: 2.004324\t [   64/59968]\n",
      "Loss: 1.976381\t [ 6464/59968]\n",
      "Loss: 1.983155\t [12864/59968]\n",
      "Loss: 1.976826\t [19264/59968]\n",
      "Loss: 1.991217\t [25664/59968]\n",
      "Loss: 2.009407\t [32064/59968]\n",
      "Loss: 1.973545\t [38464/59968]\n",
      "Loss: 1.970374\t [44864/59968]\n",
      "Loss: 1.975645 Accuracy: 93.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print(f\"Epoch {i + 1}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    train(cnn, loss_fn)\n",
    "    loss, accuracy = validate(cnn, loss_fn)\n",
    "    print(f\"Loss: {loss:>7f} Accuracy: {accuracy:>5f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.18%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
