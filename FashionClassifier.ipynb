{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split # loads data either in chunks or full\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets # open datasets\n",
    "from torchvision.transforms import ToTensor # transfor data to tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing gpu for training\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training and test data from open datasets.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train_size = int(len(train_data) * 0.8)  # 80% of the data for training\n",
    "val_size = len(train_data) - train_size  # 20% of the data for validation\n",
    "train_subset, val_subset = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_subset, batch_size=64) \n",
    "val_dataloader = DataLoader(val_subset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Coat, Number: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting and understanding images and labels with first batch\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "idx = torch.randint(0, 64, (1,)).item()\n",
    "image = images[idx].squeeze()\n",
    "label = labels[idx]\n",
    "print(f\"Name: {labels_map[label.item()]}, Number: {label.item()}\")\n",
    "plt.imshow(image, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, parameters, lr, name):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "        self.name = name\n",
    "\n",
    "        self.momentum = 0.9\n",
    "        self.velocities = [torch.zeros_like(p) for p in parameters]\n",
    "\n",
    "        self.decay_rate = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.sq_grads = [torch.zeros_like(p) for p in parameters]\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.m_t = [torch.zeros_like(p) for p in parameters]\n",
    "        self.v_t = [torch.zeros_like(p) for p in parameters]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        if self.name == \"stochastic\":\n",
    "            self.stochastic_step()\n",
    "        elif self.name == \"momentum\":\n",
    "            self.momentum_step()\n",
    "        elif self.name == \"RMSprop\":\n",
    "            self.RMSprop_step()\n",
    "        elif self.name == \"Adam\":\n",
    "            self.Adam_step()\n",
    "        else:\n",
    "            print(\"no valid optimizer with such name\")\n",
    "\n",
    "    def stochastic_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                if param is not None:\n",
    "                    param -= param.grad * self.lr\n",
    "                    # param.grad.zero_()\n",
    "\n",
    "    def momentum_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param, velocity in zip(self.parameters, self.velocities):\n",
    "                if param is not None:\n",
    "                    # view momentum as the mass that scales the last velocity a bit but still gives more direction\n",
    "                    # the rest is just the stochatic gradient descent\n",
    "                    velocity.mul_(self.momentum).add_(param.grad, alpha=self.lr)\n",
    "                    param.sub_(velocity)\n",
    "                    # param.grad.zero_()\n",
    "\n",
    "                    # another way\n",
    "                    # higher the momentum closer it pays attention to the upcoming points\n",
    "                    # lower the momentum closer it pays attention to the previous points\n",
    "                    # velocity.mul_(self.momentum).add_(param.grad, alpha=(1 - self.momentum))\n",
    "                    # param.sub_(velocity, alpha=self.lr)\n",
    "                    # param.grad.zero_()\n",
    "    \n",
    "    def RMSprop_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param, sq_grad in zip(self.parameters, self.sq_grads):\n",
    "                if param.grad is not None:\n",
    "                    sq_grad.mul_(self.decay_rate).addcmul_(param.grad, param.grad, value=1 - self.decay_rate)\n",
    "                    sqrt = sq_grad.sqrt().add(self.epsilon)\n",
    "                    adjusted_grad = param.grad / sqrt\n",
    "                    param.sub_(adjusted_grad, alpha=self.lr)\n",
    "\n",
    "    def Adam_step(self):\n",
    "        with torch.no_grad():\n",
    "            self.t += 1\n",
    "            for param, m, v in zip(self.parameters, self.m_t, self.v_t):\n",
    "                if param is not None:\n",
    "                    # Update biased first moment estimate\n",
    "                    m.mul_(self.beta1).add_(param.grad, alpha=1 - self.beta1)\n",
    "                    # Update biased second raw moment estimate\n",
    "                    v.mul_(self.beta2).addcmul_(param.grad, param.grad, value=1 - self.beta2)\n",
    "                    # Compute bias-corrected first moment estimate\n",
    "                    m_hat = m / (1 - self.beta1 ** self.t)\n",
    "                    # Compute bias-corrected second raw moment estimate\n",
    "                    v_hat = v / (1 - self.beta2 ** self.t)\n",
    "                    # Update parameters\n",
    "                    param.sub_(m_hat / (v_hat.sqrt().add(self.epsilon)), alpha=self.lr)\n",
    "\n",
    "    def zero_grads(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                if param.grad is not None:\n",
    "                    param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: \n",
    "    # nin is the number of input (prev layer)\n",
    "    # nout is the number of output (next layer)\n",
    "    def __init__(self, nin, nout, processor=\"cuda:0\"):\n",
    "        self.w = torch.randn((nin, nout), requires_grad=True, device=processor)\n",
    "        self.b = torch.randn(1, requires_grad=True, device=processor)\n",
    "    \n",
    "    # x is the input in (batch, input)\n",
    "    def __call__(self, x):\n",
    "        eq = torch.matmul(x, self.w) + self.b\n",
    "        out = torch.tanh(eq)\n",
    "        return out # returns (batch, output # of neurons for next layer)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts, lr, optimizer=\"stochastic\", processor=\"cuda:0\"):\n",
    "        self.lr = lr\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "        self.optimizer = Optimizer(self.parameters(), lr, optimizer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        self.optimizer.step()\n",
    "        # print(self.optimizer.velocities[0])\n",
    "\n",
    "    def zero_grads(self):\n",
    "        self.optimizer.zero_grads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mlp, loss_fn):\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "        x_flattened = x.view(x.size(0), -1)\n",
    "\n",
    "        output = mlp(x_flattened)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        mlp.zero_grads()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # for param in mlp.parameters():\n",
    "        #     print(torch.max(param.grad))\n",
    "\n",
    "        mlp.update_parameters()\n",
    "\n",
    "        if batch % 200 == 0:\n",
    "            print(f\"Loss: {loss:>7f}\\t [{((batch + 1) * 64):>5d}/{937 * 64}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(mlp):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dataloader:\n",
    "            x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "            x_falttened = x.view(x.size(0), -1)\n",
    "            output = mlp(x_falttened)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            tot += y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mlp):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in test_dataloader:\n",
    "            test_x, test_y = test_x.to(\"cuda:0\"), test_y.to(\"cuda:0\")\n",
    "\n",
    "            test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "            output = mlp(test_x_flattened)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(test_y.view_as(pred)).sum().item()\n",
    "            tot += test_y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(optimizers, learning_rates, neurons, epoch, num_trials):\n",
    "    best_accuracy = 0.0\n",
    "    best_optimizer = \"\"\n",
    "    best_lr = 0.0\n",
    "    best_epochs = 0\n",
    "    best_neurons = []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        optimizer = random.choice(optimizers)\n",
    "        lr = random.choice(learning_rates)\n",
    "        neuron = random.choice(neurons)\n",
    "                    \n",
    "        mlp = MLP(784, neuron, lr=lr, optimizer=optimizer)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"------------------------------------------------------------------------------------\")\n",
    "        print(f\"trial: {trial} optimizer: {optimizer}\\t lr: {lr}\\t #neurons: {neuron}\")\n",
    "\n",
    "        new_accuracy = 0.0\n",
    "        prev_accuracy = -1\n",
    "\n",
    "        for i in range(epoch):\n",
    "            if prev_accuracy == new_accuracy:\n",
    "                print(f\"\\tNo accuracy change {prev_accuracy:.2f} == {new_accuracy:.2f}\")\n",
    "                break\n",
    "            prev_accuracy = new_accuracy\n",
    "            train(mlp, loss_fn)\n",
    "            new_accuracy = validate(mlp)\n",
    "            print(f\"\\tEpoch {i + 1} Accuracy: {new_accuracy:.2f}\")\n",
    "\n",
    "            if new_accuracy > best_accuracy:\n",
    "                best_accuracy = new_accuracy\n",
    "                best_optimizer = optimizer\n",
    "                best_lr = lr\n",
    "                best_epochs = i + 1\n",
    "                best_neurons = neuron\n",
    "        \n",
    "        print(f\"accuracy: {new_accuracy:.2f}\\n\")\n",
    "\n",
    "    print(f\"accuracy: {best_accuracy:.2f}, optimizer: {best_optimizer}, lr: {best_lr}, epoch {best_epochs}, #neurons {best_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "trial: 0 optimizer: Adam\t lr: 0.0001\t #neurons: [512, 256, 10]\n",
      "\tEpoch 1 Accuracy: 24.18\n",
      "\tEpoch 2 Accuracy: 44.98\n",
      "\tEpoch 3 Accuracy: 54.34\n",
      "\tEpoch 4 Accuracy: 59.09\n",
      "\tEpoch 5 Accuracy: 61.89\n",
      "\tEpoch 6 Accuracy: 64.43\n",
      "\tEpoch 7 Accuracy: 65.72\n",
      "\tEpoch 8 Accuracy: 66.96\n",
      "\tEpoch 9 Accuracy: 68.42\n",
      "\tEpoch 10 Accuracy: 68.97\n",
      "\tEpoch 11 Accuracy: 69.73\n",
      "\tEpoch 12 Accuracy: 70.23\n",
      "\tEpoch 13 Accuracy: 70.87\n",
      "\tEpoch 14 Accuracy: 71.53\n",
      "\tEpoch 15 Accuracy: 71.99\n",
      "\tEpoch 16 Accuracy: 72.21\n",
      "\tEpoch 17 Accuracy: 72.49\n",
      "\tEpoch 18 Accuracy: 72.74\n",
      "\tEpoch 19 Accuracy: 73.09\n",
      "\tEpoch 20 Accuracy: 73.67\n",
      "\tEpoch 21 Accuracy: 73.67\n",
      "\tNo accuracy change 73.67 == 73.67\n",
      "accuracy: 73.67\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 1 optimizer: RMSprop\t lr: 0.3\t #neurons: [256, 48, 10]\n",
      "\tEpoch 1 Accuracy: 9.39\n",
      "\tEpoch 2 Accuracy: 9.39\n",
      "\tNo accuracy change 9.39 == 9.39\n",
      "accuracy: 9.39\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 2 optimizer: RMSprop\t lr: 0.1\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.07\n",
      "\tEpoch 2 Accuracy: 10.07\n",
      "\tNo accuracy change 10.07 == 10.07\n",
      "accuracy: 10.07\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 3 optimizer: momentum\t lr: 0.35\t #neurons: [48, 48, 10]\n",
      "\tEpoch 1 Accuracy: 71.67\n",
      "\tEpoch 2 Accuracy: 74.12\n",
      "\tEpoch 3 Accuracy: 75.88\n",
      "\tEpoch 4 Accuracy: 77.62\n",
      "\tEpoch 5 Accuracy: 77.58\n",
      "\tEpoch 6 Accuracy: 77.38\n",
      "\tEpoch 7 Accuracy: 78.84\n",
      "\tEpoch 8 Accuracy: 79.49\n",
      "\tEpoch 9 Accuracy: 80.28\n",
      "\tEpoch 10 Accuracy: 80.54\n",
      "\tEpoch 11 Accuracy: 80.33\n",
      "\tEpoch 12 Accuracy: 80.52\n",
      "\tEpoch 13 Accuracy: 80.49\n",
      "\tEpoch 14 Accuracy: 80.85\n",
      "\tEpoch 15 Accuracy: 81.52\n",
      "\tEpoch 16 Accuracy: 81.24\n",
      "\tEpoch 17 Accuracy: 81.09\n",
      "\tEpoch 18 Accuracy: 81.72\n",
      "\tEpoch 19 Accuracy: 81.33\n",
      "\tEpoch 20 Accuracy: 80.72\n",
      "\tEpoch 21 Accuracy: 81.03\n",
      "\tEpoch 22 Accuracy: 82.42\n",
      "\tEpoch 23 Accuracy: 82.10\n",
      "\tEpoch 24 Accuracy: 81.12\n",
      "\tEpoch 25 Accuracy: 82.39\n",
      "\tEpoch 26 Accuracy: 82.99\n",
      "\tEpoch 27 Accuracy: 81.75\n",
      "\tEpoch 28 Accuracy: 82.86\n",
      "\tEpoch 29 Accuracy: 82.58\n",
      "\tEpoch 30 Accuracy: 82.23\n",
      "accuracy: 82.23\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 4 optimizer: RMSprop\t lr: 0.18\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.49\n",
      "\tEpoch 2 Accuracy: 10.49\n",
      "\tNo accuracy change 10.49 == 10.49\n",
      "accuracy: 10.49\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 5 optimizer: Adam\t lr: 0.01\t #neurons: [512, 512, 10]\n",
      "\tEpoch 1 Accuracy: 46.88\n",
      "\tEpoch 2 Accuracy: 38.10\n",
      "\tEpoch 3 Accuracy: 34.88\n",
      "\tEpoch 4 Accuracy: 27.06\n",
      "\tEpoch 5 Accuracy: 20.39\n",
      "\tEpoch 6 Accuracy: 19.48\n",
      "\tEpoch 7 Accuracy: 19.30\n",
      "\tEpoch 8 Accuracy: 16.50\n",
      "\tEpoch 9 Accuracy: 18.25\n",
      "\tEpoch 10 Accuracy: 17.12\n",
      "\tEpoch 11 Accuracy: 19.36\n",
      "\tEpoch 12 Accuracy: 19.40\n",
      "\tEpoch 13 Accuracy: 9.40\n",
      "\tEpoch 14 Accuracy: 9.40\n",
      "\tNo accuracy change 9.40 == 9.40\n",
      "accuracy: 9.40\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 6 optimizer: RMSprop\t lr: 1e-07\t #neurons: [256, 512, 10]\n",
      "\tEpoch 1 Accuracy: 12.47\n",
      "\tEpoch 2 Accuracy: 12.47\n",
      "\tEpoch 3 Accuracy: 12.47\n",
      "\tEpoch 4 Accuracy: 12.47\n",
      "\tNo accuracy change 12.47 == 12.47\n",
      "accuracy: 12.47\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 7 optimizer: momentum\t lr: 0.18\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 56.42\n",
      "\tEpoch 2 Accuracy: 63.30\n",
      "\tEpoch 3 Accuracy: 65.60\n",
      "\tEpoch 4 Accuracy: 67.58\n",
      "\tEpoch 5 Accuracy: 68.53\n",
      "\tEpoch 6 Accuracy: 68.94\n",
      "\tEpoch 7 Accuracy: 70.08\n",
      "\tEpoch 8 Accuracy: 69.83\n",
      "\tEpoch 9 Accuracy: 68.53\n",
      "\tEpoch 10 Accuracy: 71.92\n",
      "\tEpoch 11 Accuracy: 71.32\n",
      "\tEpoch 12 Accuracy: 70.73\n",
      "\tEpoch 13 Accuracy: 68.78\n",
      "\tEpoch 14 Accuracy: 71.23\n",
      "\tEpoch 15 Accuracy: 71.08\n",
      "\tEpoch 16 Accuracy: 73.48\n",
      "\tEpoch 17 Accuracy: 72.05\n",
      "\tEpoch 18 Accuracy: 73.26\n",
      "\tEpoch 19 Accuracy: 73.66\n",
      "\tEpoch 20 Accuracy: 74.43\n",
      "\tEpoch 21 Accuracy: 72.94\n",
      "\tEpoch 22 Accuracy: 72.65\n",
      "\tEpoch 23 Accuracy: 73.09\n",
      "\tEpoch 24 Accuracy: 72.28\n",
      "\tEpoch 25 Accuracy: 72.05\n",
      "\tEpoch 26 Accuracy: 71.92\n",
      "\tEpoch 27 Accuracy: 73.78\n",
      "\tEpoch 28 Accuracy: 75.14\n",
      "\tEpoch 29 Accuracy: 75.13\n",
      "\tEpoch 30 Accuracy: 75.16\n",
      "accuracy: 75.16\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 8 optimizer: momentum\t lr: 0.14\t #neurons: [256, 512, 10]\n",
      "\tEpoch 1 Accuracy: 57.78\n",
      "\tEpoch 2 Accuracy: 60.70\n",
      "\tEpoch 3 Accuracy: 62.74\n",
      "\tEpoch 4 Accuracy: 61.34\n",
      "\tEpoch 5 Accuracy: 64.83\n",
      "\tEpoch 6 Accuracy: 65.17\n",
      "\tEpoch 7 Accuracy: 67.07\n",
      "\tEpoch 8 Accuracy: 67.68\n",
      "\tEpoch 9 Accuracy: 68.17\n",
      "\tEpoch 10 Accuracy: 68.79\n",
      "\tEpoch 11 Accuracy: 69.30\n",
      "\tEpoch 12 Accuracy: 69.15\n",
      "\tEpoch 13 Accuracy: 69.34\n",
      "\tEpoch 14 Accuracy: 70.29\n",
      "\tEpoch 15 Accuracy: 69.75\n",
      "\tEpoch 16 Accuracy: 70.44\n",
      "\tEpoch 17 Accuracy: 70.72\n",
      "\tEpoch 18 Accuracy: 70.01\n",
      "\tEpoch 19 Accuracy: 70.90\n",
      "\tEpoch 20 Accuracy: 70.47\n",
      "\tEpoch 21 Accuracy: 70.86\n",
      "\tEpoch 22 Accuracy: 71.00\n",
      "\tEpoch 23 Accuracy: 70.76\n",
      "\tEpoch 24 Accuracy: 71.04\n",
      "\tEpoch 25 Accuracy: 71.04\n",
      "\tNo accuracy change 71.04 == 71.04\n",
      "accuracy: 71.04\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 9 optimizer: momentum\t lr: 0.3\t #neurons: [512, 256, 10]\n",
      "\tEpoch 1 Accuracy: 67.96\n",
      "\tEpoch 2 Accuracy: 70.63\n",
      "\tEpoch 3 Accuracy: 74.65\n",
      "\tEpoch 4 Accuracy: 74.80\n",
      "\tEpoch 5 Accuracy: 75.70\n",
      "\tEpoch 6 Accuracy: 75.26\n",
      "\tEpoch 7 Accuracy: 72.46\n",
      "\tEpoch 8 Accuracy: 77.63\n",
      "\tEpoch 9 Accuracy: 76.98\n",
      "\tEpoch 10 Accuracy: 77.88\n",
      "\tEpoch 11 Accuracy: 78.31\n",
      "\tEpoch 12 Accuracy: 75.74\n",
      "\tEpoch 13 Accuracy: 78.84\n",
      "\tEpoch 14 Accuracy: 78.94\n",
      "\tEpoch 15 Accuracy: 78.99\n",
      "\tEpoch 16 Accuracy: 79.31\n",
      "\tEpoch 17 Accuracy: 79.30\n",
      "\tEpoch 18 Accuracy: 78.54\n",
      "\tEpoch 19 Accuracy: 79.62\n",
      "\tEpoch 20 Accuracy: 78.18\n",
      "\tEpoch 21 Accuracy: 77.90\n",
      "\tEpoch 22 Accuracy: 80.60\n",
      "\tEpoch 23 Accuracy: 79.33\n",
      "\tEpoch 24 Accuracy: 79.99\n",
      "\tEpoch 25 Accuracy: 79.60\n",
      "\tEpoch 26 Accuracy: 80.25\n",
      "\tEpoch 27 Accuracy: 80.21\n",
      "\tEpoch 28 Accuracy: 80.56\n",
      "\tEpoch 29 Accuracy: 80.60\n",
      "\tEpoch 30 Accuracy: 80.47\n",
      "accuracy: 80.47\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 10 optimizer: RMSprop\t lr: 0.001\t #neurons: [256, 512, 10]\n",
      "\tEpoch 1 Accuracy: 58.12\n",
      "\tEpoch 2 Accuracy: 62.29\n",
      "\tEpoch 3 Accuracy: 63.19\n",
      "\tEpoch 4 Accuracy: 63.89\n",
      "\tEpoch 5 Accuracy: 64.15\n",
      "\tEpoch 6 Accuracy: 64.64\n",
      "\tEpoch 7 Accuracy: 64.28\n",
      "\tEpoch 8 Accuracy: 65.60\n",
      "\tEpoch 9 Accuracy: 66.07\n",
      "\tEpoch 10 Accuracy: 65.90\n",
      "\tEpoch 11 Accuracy: 64.89\n",
      "\tEpoch 12 Accuracy: 65.70\n",
      "\tEpoch 13 Accuracy: 66.19\n",
      "\tEpoch 14 Accuracy: 65.91\n",
      "\tEpoch 15 Accuracy: 66.84\n",
      "\tEpoch 16 Accuracy: 67.72\n",
      "\tEpoch 17 Accuracy: 67.13\n",
      "\tEpoch 18 Accuracy: 67.50\n",
      "\tEpoch 19 Accuracy: 67.50\n",
      "\tNo accuracy change 67.50 == 67.50\n",
      "accuracy: 67.50\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 11 optimizer: Adam\t lr: 0.2\t #neurons: [256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 9.72\n",
      "\tEpoch 2 Accuracy: 9.72\n",
      "\tNo accuracy change 9.72 == 9.72\n",
      "accuracy: 9.72\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 12 optimizer: momentum\t lr: 0.0001\t #neurons: [512, 512, 10]\n",
      "\tEpoch 1 Accuracy: 9.55\n",
      "\tEpoch 2 Accuracy: 9.68\n",
      "\tEpoch 3 Accuracy: 9.69\n",
      "\tEpoch 4 Accuracy: 9.84\n",
      "\tEpoch 5 Accuracy: 9.85\n",
      "\tEpoch 6 Accuracy: 9.84\n",
      "\tEpoch 7 Accuracy: 9.92\n",
      "\tEpoch 8 Accuracy: 9.94\n",
      "\tEpoch 9 Accuracy: 9.94\n",
      "\tNo accuracy change 9.94 == 9.94\n",
      "accuracy: 9.94\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 13 optimizer: Adam\t lr: 0.1\t #neurons: [256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.38\n",
      "\tEpoch 2 Accuracy: 10.38\n",
      "\tNo accuracy change 10.38 == 10.38\n",
      "accuracy: 10.38\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 14 optimizer: stochastic\t lr: 0.35\t #neurons: [48, 48, 48, 10]\n",
      "\tEpoch 1 Accuracy: 42.79\n",
      "\tEpoch 2 Accuracy: 54.79\n",
      "\tEpoch 3 Accuracy: 60.23\n",
      "\tEpoch 4 Accuracy: 62.78\n",
      "\tEpoch 5 Accuracy: 63.92\n",
      "\tEpoch 6 Accuracy: 65.67\n",
      "\tEpoch 7 Accuracy: 66.39\n",
      "\tEpoch 8 Accuracy: 67.08\n",
      "\tEpoch 9 Accuracy: 68.42\n",
      "\tEpoch 10 Accuracy: 68.69\n",
      "\tEpoch 11 Accuracy: 68.77\n",
      "\tEpoch 12 Accuracy: 69.14\n",
      "\tEpoch 13 Accuracy: 69.55\n",
      "\tEpoch 14 Accuracy: 69.48\n",
      "\tEpoch 15 Accuracy: 69.70\n",
      "\tEpoch 16 Accuracy: 70.34\n",
      "\tEpoch 17 Accuracy: 70.27\n",
      "\tEpoch 18 Accuracy: 71.18\n",
      "\tEpoch 19 Accuracy: 72.04\n",
      "\tEpoch 20 Accuracy: 71.59\n",
      "\tEpoch 21 Accuracy: 71.11\n",
      "\tEpoch 22 Accuracy: 71.31\n",
      "\tEpoch 23 Accuracy: 71.51\n",
      "\tEpoch 24 Accuracy: 71.79\n",
      "\tEpoch 25 Accuracy: 72.28\n",
      "\tEpoch 26 Accuracy: 72.09\n",
      "\tEpoch 27 Accuracy: 72.45\n",
      "\tEpoch 28 Accuracy: 74.17\n",
      "\tEpoch 29 Accuracy: 73.18\n",
      "\tEpoch 30 Accuracy: 73.61\n",
      "accuracy: 73.61\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 15 optimizer: Adam\t lr: 0.35\t #neurons: [256, 10]\n",
      "\tEpoch 1 Accuracy: 10.07\n",
      "\tEpoch 2 Accuracy: 10.07\n",
      "\tNo accuracy change 10.07 == 10.07\n",
      "accuracy: 10.07\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 16 optimizer: Adam\t lr: 1e-08\t #neurons: [256, 48, 10]\n",
      "\tEpoch 1 Accuracy: 10.37\n",
      "\tEpoch 2 Accuracy: 10.37\n",
      "\tNo accuracy change 10.37 == 10.37\n",
      "accuracy: 10.37\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 17 optimizer: momentum\t lr: 0.35\t #neurons: [256, 10]\n",
      "\tEpoch 1 Accuracy: 69.84\n",
      "\tEpoch 2 Accuracy: 74.30\n",
      "\tEpoch 3 Accuracy: 78.57\n",
      "\tEpoch 4 Accuracy: 79.43\n",
      "\tEpoch 5 Accuracy: 80.12\n",
      "\tEpoch 6 Accuracy: 80.73\n",
      "\tEpoch 7 Accuracy: 79.61\n",
      "\tEpoch 8 Accuracy: 80.86\n",
      "\tEpoch 9 Accuracy: 81.83\n",
      "\tEpoch 10 Accuracy: 81.88\n",
      "\tEpoch 11 Accuracy: 82.06\n",
      "\tEpoch 12 Accuracy: 81.88\n",
      "\tEpoch 13 Accuracy: 82.63\n",
      "\tEpoch 14 Accuracy: 82.58\n",
      "\tEpoch 15 Accuracy: 82.70\n",
      "\tEpoch 16 Accuracy: 82.88\n",
      "\tEpoch 17 Accuracy: 82.73\n",
      "\tEpoch 18 Accuracy: 82.98\n",
      "\tEpoch 19 Accuracy: 83.17\n",
      "\tEpoch 20 Accuracy: 83.33\n",
      "\tEpoch 21 Accuracy: 82.88\n",
      "\tEpoch 22 Accuracy: 82.98\n",
      "\tEpoch 23 Accuracy: 84.03\n",
      "\tEpoch 24 Accuracy: 83.36\n",
      "\tEpoch 25 Accuracy: 83.62\n",
      "\tEpoch 26 Accuracy: 83.61\n",
      "\tEpoch 27 Accuracy: 83.65\n",
      "\tEpoch 28 Accuracy: 83.24\n",
      "\tEpoch 29 Accuracy: 83.77\n",
      "\tEpoch 30 Accuracy: 83.71\n",
      "accuracy: 83.71\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 18 optimizer: RMSprop\t lr: 0.18\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 9.72\n",
      "\tEpoch 2 Accuracy: 9.72\n",
      "\tNo accuracy change 9.72 == 9.72\n",
      "accuracy: 9.72\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 19 optimizer: momentum\t lr: 0.1\t #neurons: [256, 512, 48, 10]\n",
      "\tEpoch 1 Accuracy: 50.60\n",
      "\tEpoch 2 Accuracy: 57.69\n",
      "\tEpoch 3 Accuracy: 60.61\n",
      "\tEpoch 4 Accuracy: 62.02\n",
      "\tEpoch 5 Accuracy: 62.91\n",
      "\tEpoch 6 Accuracy: 62.52\n",
      "\tEpoch 7 Accuracy: 64.11\n",
      "\tEpoch 8 Accuracy: 63.29\n",
      "\tEpoch 9 Accuracy: 65.47\n",
      "\tEpoch 10 Accuracy: 65.72\n",
      "\tEpoch 11 Accuracy: 67.03\n",
      "\tEpoch 12 Accuracy: 66.07\n",
      "\tEpoch 13 Accuracy: 66.18\n",
      "\tEpoch 14 Accuracy: 67.01\n",
      "\tEpoch 15 Accuracy: 67.29\n",
      "\tEpoch 16 Accuracy: 67.20\n",
      "\tEpoch 17 Accuracy: 67.44\n",
      "\tEpoch 18 Accuracy: 67.82\n",
      "\tEpoch 19 Accuracy: 67.23\n",
      "\tEpoch 20 Accuracy: 67.90\n",
      "\tEpoch 21 Accuracy: 68.66\n",
      "\tEpoch 22 Accuracy: 68.51\n",
      "\tEpoch 23 Accuracy: 68.69\n",
      "\tEpoch 24 Accuracy: 68.43\n",
      "\tEpoch 25 Accuracy: 68.88\n",
      "\tEpoch 26 Accuracy: 68.77\n",
      "\tEpoch 27 Accuracy: 68.78\n",
      "\tEpoch 28 Accuracy: 68.61\n",
      "\tEpoch 29 Accuracy: 69.28\n",
      "\tEpoch 30 Accuracy: 69.16\n",
      "accuracy: 69.16\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 20 optimizer: stochastic\t lr: 0.14\t #neurons: [256, 512, 48, 10]\n",
      "\tEpoch 1 Accuracy: 25.56\n",
      "\tEpoch 2 Accuracy: 40.83\n",
      "\tEpoch 3 Accuracy: 50.20\n",
      "\tEpoch 4 Accuracy: 56.33\n",
      "\tEpoch 5 Accuracy: 59.55\n",
      "\tEpoch 6 Accuracy: 61.38\n",
      "\tEpoch 7 Accuracy: 63.16\n",
      "\tEpoch 8 Accuracy: 64.44\n",
      "\tEpoch 9 Accuracy: 65.34\n",
      "\tEpoch 10 Accuracy: 66.35\n",
      "\tEpoch 11 Accuracy: 67.24\n",
      "\tEpoch 12 Accuracy: 68.03\n",
      "\tEpoch 13 Accuracy: 68.92\n",
      "\tEpoch 14 Accuracy: 69.73\n",
      "\tEpoch 15 Accuracy: 70.58\n",
      "\tEpoch 16 Accuracy: 70.75\n",
      "\tEpoch 17 Accuracy: 71.23\n",
      "\tEpoch 18 Accuracy: 71.86\n",
      "\tEpoch 19 Accuracy: 71.89\n",
      "\tEpoch 20 Accuracy: 72.18\n",
      "\tEpoch 21 Accuracy: 72.17\n",
      "\tEpoch 22 Accuracy: 72.78\n",
      "\tEpoch 23 Accuracy: 73.18\n",
      "\tEpoch 24 Accuracy: 73.11\n",
      "\tEpoch 25 Accuracy: 73.40\n",
      "\tEpoch 26 Accuracy: 74.02\n",
      "\tEpoch 27 Accuracy: 74.28\n",
      "\tEpoch 28 Accuracy: 74.21\n",
      "\tEpoch 29 Accuracy: 74.55\n",
      "\tEpoch 30 Accuracy: 74.89\n",
      "accuracy: 74.89\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 21 optimizer: stochastic\t lr: 1e-07\t #neurons: [512, 10]\n",
      "\tEpoch 1 Accuracy: 13.16\n",
      "\tEpoch 2 Accuracy: 13.16\n",
      "\tNo accuracy change 13.16 == 13.16\n",
      "accuracy: 13.16\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 22 optimizer: stochastic\t lr: 1e-08\t #neurons: [512, 512, 10]\n",
      "\tEpoch 1 Accuracy: 14.98\n",
      "\tEpoch 2 Accuracy: 14.98\n",
      "\tNo accuracy change 14.98 == 14.98\n",
      "accuracy: 14.98\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 23 optimizer: Adam\t lr: 0.18\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.07\n",
      "\tEpoch 2 Accuracy: 10.07\n",
      "\tNo accuracy change 10.07 == 10.07\n",
      "accuracy: 10.07\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 24 optimizer: RMSprop\t lr: 0.2\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 9.72\n",
      "\tEpoch 2 Accuracy: 9.72\n",
      "\tNo accuracy change 9.72 == 9.72\n",
      "accuracy: 9.72\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 25 optimizer: stochastic\t lr: 0.01\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.86\n",
      "\tEpoch 2 Accuracy: 12.13\n",
      "\tEpoch 3 Accuracy: 13.01\n",
      "\tEpoch 4 Accuracy: 13.63\n",
      "\tEpoch 5 Accuracy: 14.46\n",
      "\tEpoch 6 Accuracy: 15.18\n",
      "\tEpoch 7 Accuracy: 15.72\n",
      "\tEpoch 8 Accuracy: 16.53\n",
      "\tEpoch 9 Accuracy: 17.19\n",
      "\tEpoch 10 Accuracy: 17.45\n",
      "\tEpoch 11 Accuracy: 18.28\n",
      "\tEpoch 12 Accuracy: 18.86\n",
      "\tEpoch 13 Accuracy: 19.19\n",
      "\tEpoch 14 Accuracy: 19.83\n",
      "\tEpoch 15 Accuracy: 20.35\n",
      "\tEpoch 16 Accuracy: 20.97\n",
      "\tEpoch 17 Accuracy: 21.47\n",
      "\tEpoch 18 Accuracy: 21.77\n",
      "\tEpoch 19 Accuracy: 22.38\n",
      "\tEpoch 20 Accuracy: 22.91\n",
      "\tEpoch 21 Accuracy: 23.60\n",
      "\tEpoch 22 Accuracy: 24.13\n",
      "\tEpoch 23 Accuracy: 24.72\n",
      "\tEpoch 24 Accuracy: 25.24\n",
      "\tEpoch 25 Accuracy: 25.90\n",
      "\tEpoch 26 Accuracy: 26.51\n",
      "\tEpoch 27 Accuracy: 26.72\n",
      "\tEpoch 28 Accuracy: 27.70\n",
      "\tEpoch 29 Accuracy: 27.87\n",
      "\tEpoch 30 Accuracy: 28.24\n",
      "accuracy: 28.24\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 26 optimizer: Adam\t lr: 1e-05\t #neurons: [256, 512, 10]\n",
      "\tEpoch 1 Accuracy: 14.88\n",
      "\tEpoch 2 Accuracy: 16.28\n",
      "\tEpoch 3 Accuracy: 17.90\n",
      "\tEpoch 4 Accuracy: 19.37\n",
      "\tEpoch 5 Accuracy: 20.92\n",
      "\tEpoch 6 Accuracy: 22.50\n",
      "\tEpoch 7 Accuracy: 23.76\n",
      "\tEpoch 8 Accuracy: 25.06\n",
      "\tEpoch 9 Accuracy: 26.48\n",
      "\tEpoch 10 Accuracy: 27.68\n",
      "\tEpoch 11 Accuracy: 28.89\n",
      "\tEpoch 12 Accuracy: 30.14\n",
      "\tEpoch 13 Accuracy: 31.32\n",
      "\tEpoch 14 Accuracy: 32.73\n",
      "\tEpoch 15 Accuracy: 33.65\n",
      "\tEpoch 16 Accuracy: 34.56\n",
      "\tEpoch 17 Accuracy: 35.41\n",
      "\tEpoch 18 Accuracy: 36.18\n",
      "\tEpoch 19 Accuracy: 37.01\n",
      "\tEpoch 20 Accuracy: 37.78\n",
      "\tEpoch 21 Accuracy: 38.49\n",
      "\tEpoch 22 Accuracy: 39.11\n",
      "\tEpoch 23 Accuracy: 39.86\n",
      "\tEpoch 24 Accuracy: 40.56\n",
      "\tEpoch 25 Accuracy: 41.08\n",
      "\tEpoch 26 Accuracy: 41.59\n",
      "\tEpoch 27 Accuracy: 42.32\n",
      "\tEpoch 28 Accuracy: 42.88\n",
      "\tEpoch 29 Accuracy: 43.48\n",
      "\tEpoch 30 Accuracy: 44.03\n",
      "accuracy: 44.03\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 27 optimizer: RMSprop\t lr: 0.01\t #neurons: [48, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.07\n",
      "\tEpoch 2 Accuracy: 10.07\n",
      "\tNo accuracy change 10.07 == 10.07\n",
      "accuracy: 10.07\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 28 optimizer: Adam\t lr: 0.01\t #neurons: [256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 54.43\n",
      "\tEpoch 2 Accuracy: 54.41\n",
      "\tEpoch 3 Accuracy: 54.18\n",
      "\tEpoch 4 Accuracy: 53.61\n",
      "\tEpoch 5 Accuracy: 53.94\n",
      "\tEpoch 6 Accuracy: 54.40\n",
      "\tEpoch 7 Accuracy: 54.23\n",
      "\tEpoch 8 Accuracy: 53.99\n",
      "\tEpoch 9 Accuracy: 51.05\n",
      "\tEpoch 10 Accuracy: 53.43\n",
      "\tEpoch 11 Accuracy: 55.02\n",
      "\tEpoch 12 Accuracy: 42.80\n",
      "\tEpoch 13 Accuracy: 52.83\n",
      "\tEpoch 14 Accuracy: 47.44\n",
      "\tEpoch 15 Accuracy: 45.22\n",
      "\tEpoch 16 Accuracy: 50.61\n",
      "\tEpoch 17 Accuracy: 39.12\n",
      "\tEpoch 18 Accuracy: 43.55\n",
      "\tEpoch 19 Accuracy: 35.71\n",
      "\tEpoch 20 Accuracy: 36.48\n",
      "\tEpoch 21 Accuracy: 26.25\n",
      "\tEpoch 22 Accuracy: 35.64\n",
      "\tEpoch 23 Accuracy: 34.90\n",
      "\tEpoch 24 Accuracy: 35.24\n",
      "\tEpoch 25 Accuracy: 36.52\n",
      "\tEpoch 26 Accuracy: 36.24\n",
      "\tEpoch 27 Accuracy: 35.08\n",
      "\tEpoch 28 Accuracy: 35.98\n",
      "\tEpoch 29 Accuracy: 35.70\n",
      "\tEpoch 30 Accuracy: 21.53\n",
      "accuracy: 21.53\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 29 optimizer: stochastic\t lr: 1e-06\t #neurons: [256, 512, 10]\n",
      "\tEpoch 1 Accuracy: 6.83\n",
      "\tEpoch 2 Accuracy: 6.83\n",
      "\tNo accuracy change 6.83 == 6.83\n",
      "accuracy: 6.83\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 30 optimizer: RMSprop\t lr: 1e-07\t #neurons: [512, 512, 10]\n",
      "\tEpoch 1 Accuracy: 8.17\n",
      "\tEpoch 2 Accuracy: 8.18\n",
      "\tEpoch 3 Accuracy: 8.20\n",
      "\tEpoch 4 Accuracy: 8.22\n",
      "\tEpoch 5 Accuracy: 8.25\n",
      "\tEpoch 6 Accuracy: 8.28\n",
      "\tEpoch 7 Accuracy: 8.32\n",
      "\tEpoch 8 Accuracy: 8.34\n",
      "\tEpoch 9 Accuracy: 8.38\n",
      "\tEpoch 10 Accuracy: 8.38\n",
      "\tEpoch 11 Accuracy: 8.40\n",
      "\tEpoch 12 Accuracy: 8.41\n",
      "\tEpoch 13 Accuracy: 8.43\n",
      "\tEpoch 14 Accuracy: 8.47\n",
      "\tEpoch 15 Accuracy: 8.48\n",
      "\tEpoch 16 Accuracy: 8.48\n",
      "\tEpoch 17 Accuracy: 8.51\n",
      "\tEpoch 18 Accuracy: 8.52\n",
      "\tEpoch 19 Accuracy: 8.53\n",
      "\tEpoch 20 Accuracy: 8.54\n",
      "\tEpoch 21 Accuracy: 8.53\n",
      "\tEpoch 22 Accuracy: 8.54\n",
      "\tEpoch 23 Accuracy: 8.55\n",
      "\tEpoch 24 Accuracy: 8.58\n",
      "\tEpoch 25 Accuracy: 8.58\n",
      "\tNo accuracy change 8.58 == 8.58\n",
      "accuracy: 8.58\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 31 optimizer: Adam\t lr: 0.25\t #neurons: [256, 512, 48, 10]\n",
      "\tEpoch 1 Accuracy: 9.93\n",
      "\tEpoch 2 Accuracy: 9.93\n",
      "\tNo accuracy change 9.93 == 9.93\n",
      "accuracy: 9.93\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 32 optimizer: stochastic\t lr: 0.25\t #neurons: [512, 10]\n",
      "\tEpoch 1 Accuracy: 30.64\n",
      "\tEpoch 2 Accuracy: 43.30\n",
      "\tEpoch 3 Accuracy: 52.23\n",
      "\tEpoch 4 Accuracy: 60.37\n",
      "\tEpoch 5 Accuracy: 65.81\n",
      "\tEpoch 6 Accuracy: 68.40\n",
      "\tEpoch 7 Accuracy: 70.02\n",
      "\tEpoch 8 Accuracy: 70.96\n",
      "\tEpoch 9 Accuracy: 71.75\n",
      "\tEpoch 10 Accuracy: 72.47\n",
      "\tEpoch 11 Accuracy: 73.02\n",
      "\tEpoch 12 Accuracy: 73.78\n",
      "\tEpoch 13 Accuracy: 74.06\n",
      "\tEpoch 14 Accuracy: 74.48\n",
      "\tEpoch 15 Accuracy: 74.67\n",
      "\tEpoch 16 Accuracy: 75.00\n",
      "\tEpoch 17 Accuracy: 75.24\n",
      "\tEpoch 18 Accuracy: 75.28\n",
      "\tEpoch 19 Accuracy: 75.68\n",
      "\tEpoch 20 Accuracy: 75.83\n",
      "\tEpoch 21 Accuracy: 75.89\n",
      "\tEpoch 22 Accuracy: 76.08\n",
      "\tEpoch 23 Accuracy: 76.29\n",
      "\tEpoch 24 Accuracy: 76.37\n",
      "\tEpoch 25 Accuracy: 76.45\n",
      "\tEpoch 26 Accuracy: 76.58\n",
      "\tEpoch 27 Accuracy: 76.74\n",
      "\tEpoch 28 Accuracy: 76.91\n",
      "\tEpoch 29 Accuracy: 77.03\n",
      "\tEpoch 30 Accuracy: 77.12\n",
      "accuracy: 77.12\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 33 optimizer: stochastic\t lr: 0.2\t #neurons: [256, 48, 10]\n",
      "\tEpoch 1 Accuracy: 33.99\n",
      "\tEpoch 2 Accuracy: 48.60\n",
      "\tEpoch 3 Accuracy: 53.92\n",
      "\tEpoch 4 Accuracy: 56.93\n",
      "\tEpoch 5 Accuracy: 58.49\n",
      "\tEpoch 6 Accuracy: 60.38\n",
      "\tEpoch 7 Accuracy: 61.59\n",
      "\tEpoch 8 Accuracy: 62.22\n",
      "\tEpoch 9 Accuracy: 63.32\n",
      "\tEpoch 10 Accuracy: 63.99\n",
      "\tEpoch 11 Accuracy: 64.61\n",
      "\tEpoch 12 Accuracy: 65.23\n",
      "\tEpoch 13 Accuracy: 65.90\n",
      "\tEpoch 14 Accuracy: 66.13\n",
      "\tEpoch 15 Accuracy: 66.62\n",
      "\tEpoch 16 Accuracy: 66.95\n",
      "\tEpoch 17 Accuracy: 67.42\n",
      "\tEpoch 18 Accuracy: 67.67\n",
      "\tEpoch 19 Accuracy: 67.83\n",
      "\tEpoch 20 Accuracy: 68.04\n",
      "\tEpoch 21 Accuracy: 68.55\n",
      "\tEpoch 22 Accuracy: 68.61\n",
      "\tEpoch 23 Accuracy: 68.84\n",
      "\tEpoch 24 Accuracy: 68.84\n",
      "\tNo accuracy change 68.84 == 68.84\n",
      "accuracy: 68.84\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 34 optimizer: stochastic\t lr: 0.14\t #neurons: [48, 48, 48, 10]\n",
      "\tEpoch 1 Accuracy: 19.43\n",
      "\tEpoch 2 Accuracy: 36.72\n",
      "\tEpoch 3 Accuracy: 48.39\n",
      "\tEpoch 4 Accuracy: 53.81\n",
      "\tEpoch 5 Accuracy: 59.20\n",
      "\tEpoch 6 Accuracy: 61.58\n",
      "\tEpoch 7 Accuracy: 63.33\n",
      "\tEpoch 8 Accuracy: 64.28\n",
      "\tEpoch 9 Accuracy: 65.08\n",
      "\tEpoch 10 Accuracy: 66.21\n",
      "\tEpoch 11 Accuracy: 66.97\n",
      "\tEpoch 12 Accuracy: 67.90\n",
      "\tEpoch 13 Accuracy: 68.39\n",
      "\tEpoch 14 Accuracy: 68.54\n",
      "\tEpoch 15 Accuracy: 69.22\n",
      "\tEpoch 16 Accuracy: 69.53\n",
      "\tEpoch 17 Accuracy: 70.22\n",
      "\tEpoch 18 Accuracy: 70.65\n",
      "\tEpoch 19 Accuracy: 71.20\n",
      "\tEpoch 20 Accuracy: 71.14\n",
      "\tEpoch 21 Accuracy: 71.59\n",
      "\tEpoch 22 Accuracy: 71.93\n",
      "\tEpoch 23 Accuracy: 72.16\n",
      "\tEpoch 24 Accuracy: 72.52\n",
      "\tEpoch 25 Accuracy: 72.61\n",
      "\tEpoch 26 Accuracy: 72.94\n",
      "\tEpoch 27 Accuracy: 73.18\n",
      "\tEpoch 28 Accuracy: 73.14\n",
      "\tEpoch 29 Accuracy: 73.28\n",
      "\tEpoch 30 Accuracy: 73.45\n",
      "accuracy: 73.45\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 35 optimizer: stochastic\t lr: 0.18\t #neurons: [256, 48, 10]\n",
      "\tEpoch 1 Accuracy: 15.34\n",
      "\tEpoch 2 Accuracy: 35.42\n",
      "\tEpoch 3 Accuracy: 49.43\n",
      "\tEpoch 4 Accuracy: 55.10\n",
      "\tEpoch 5 Accuracy: 58.48\n",
      "\tEpoch 6 Accuracy: 61.18\n",
      "\tEpoch 7 Accuracy: 63.88\n",
      "\tEpoch 8 Accuracy: 65.60\n",
      "\tEpoch 9 Accuracy: 66.77\n",
      "\tEpoch 10 Accuracy: 67.65\n",
      "\tEpoch 11 Accuracy: 68.36\n",
      "\tEpoch 12 Accuracy: 69.20\n",
      "\tEpoch 13 Accuracy: 69.81\n",
      "\tEpoch 14 Accuracy: 70.58\n",
      "\tEpoch 15 Accuracy: 71.01\n",
      "\tEpoch 16 Accuracy: 71.54\n",
      "\tEpoch 17 Accuracy: 71.68\n",
      "\tEpoch 18 Accuracy: 72.21\n",
      "\tEpoch 19 Accuracy: 72.47\n",
      "\tEpoch 20 Accuracy: 72.85\n",
      "\tEpoch 21 Accuracy: 73.12\n",
      "\tEpoch 22 Accuracy: 73.39\n",
      "\tEpoch 23 Accuracy: 73.76\n",
      "\tEpoch 24 Accuracy: 73.81\n",
      "\tEpoch 25 Accuracy: 74.08\n",
      "\tEpoch 26 Accuracy: 74.22\n",
      "\tEpoch 27 Accuracy: 74.36\n",
      "\tEpoch 28 Accuracy: 74.38\n",
      "\tEpoch 29 Accuracy: 74.42\n",
      "\tEpoch 30 Accuracy: 74.72\n",
      "accuracy: 74.72\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 36 optimizer: Adam\t lr: 1e-05\t #neurons: [512, 256, 10]\n",
      "\tEpoch 1 Accuracy: 10.75\n",
      "\tEpoch 2 Accuracy: 11.65\n",
      "\tEpoch 3 Accuracy: 12.74\n",
      "\tEpoch 4 Accuracy: 13.69\n",
      "\tEpoch 5 Accuracy: 14.69\n",
      "\tEpoch 6 Accuracy: 15.84\n",
      "\tEpoch 7 Accuracy: 16.73\n",
      "\tEpoch 8 Accuracy: 17.93\n",
      "\tEpoch 9 Accuracy: 19.29\n",
      "\tEpoch 10 Accuracy: 20.26\n",
      "\tEpoch 11 Accuracy: 21.67\n",
      "\tEpoch 12 Accuracy: 22.99\n",
      "\tEpoch 13 Accuracy: 24.17\n",
      "\tEpoch 14 Accuracy: 25.43\n",
      "\tEpoch 15 Accuracy: 26.55\n",
      "\tEpoch 16 Accuracy: 27.87\n",
      "\tEpoch 17 Accuracy: 28.89\n",
      "\tEpoch 18 Accuracy: 29.91\n",
      "\tEpoch 19 Accuracy: 30.94\n",
      "\tEpoch 20 Accuracy: 32.16\n",
      "\tEpoch 21 Accuracy: 33.27\n",
      "\tEpoch 22 Accuracy: 34.17\n",
      "\tEpoch 23 Accuracy: 34.91\n",
      "\tEpoch 24 Accuracy: 35.69\n",
      "\tEpoch 25 Accuracy: 36.48\n",
      "\tEpoch 26 Accuracy: 37.20\n",
      "\tEpoch 27 Accuracy: 37.96\n",
      "\tEpoch 28 Accuracy: 38.73\n",
      "\tEpoch 29 Accuracy: 39.32\n",
      "\tEpoch 30 Accuracy: 40.04\n",
      "accuracy: 40.04\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 37 optimizer: momentum\t lr: 0.0001\t #neurons: [512, 10]\n",
      "\tEpoch 1 Accuracy: 8.89\n",
      "\tEpoch 2 Accuracy: 8.92\n",
      "\tEpoch 3 Accuracy: 9.00\n",
      "\tEpoch 4 Accuracy: 9.04\n",
      "\tEpoch 5 Accuracy: 9.09\n",
      "\tEpoch 6 Accuracy: 9.16\n",
      "\tEpoch 7 Accuracy: 9.17\n",
      "\tEpoch 8 Accuracy: 9.17\n",
      "\tNo accuracy change 9.17 == 9.17\n",
      "accuracy: 9.17\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 38 optimizer: RMSprop\t lr: 0.01\t #neurons: [256, 48, 10]\n",
      "\tEpoch 1 Accuracy: 9.39\n",
      "\tEpoch 2 Accuracy: 9.39\n",
      "\tNo accuracy change 9.39 == 9.39\n",
      "accuracy: 9.39\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 39 optimizer: RMSprop\t lr: 0.25\t #neurons: [256, 48, 10]\n",
      "\tEpoch 1 Accuracy: 9.72\n",
      "\tEpoch 2 Accuracy: 9.93\n",
      "\tEpoch 3 Accuracy: 9.93\n",
      "\tNo accuracy change 9.93 == 9.93\n",
      "accuracy: 9.93\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 40 optimizer: Adam\t lr: 1e-07\t #neurons: [256, 512, 48, 10]\n",
      "\tEpoch 1 Accuracy: 9.76\n",
      "\tEpoch 2 Accuracy: 9.75\n",
      "\tEpoch 3 Accuracy: 9.76\n",
      "\tEpoch 4 Accuracy: 9.73\n",
      "\tEpoch 5 Accuracy: 9.74\n",
      "\tEpoch 6 Accuracy: 9.77\n",
      "\tEpoch 7 Accuracy: 9.78\n",
      "\tEpoch 8 Accuracy: 9.78\n",
      "\tEpoch 9 Accuracy: 9.78\n",
      "\tEpoch 10 Accuracy: 9.80\n",
      "\tEpoch 11 Accuracy: 9.82\n",
      "\tEpoch 12 Accuracy: 9.83\n",
      "\tEpoch 13 Accuracy: 9.83\n",
      "\tNo accuracy change 9.83 == 9.83\n",
      "accuracy: 9.83\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 41 optimizer: Adam\t lr: 0.2\t #neurons: [48, 48, 48, 10]\n",
      "\tEpoch 1 Accuracy: 9.39\n",
      "\tEpoch 2 Accuracy: 9.39\n",
      "\tNo accuracy change 9.39 == 9.39\n",
      "accuracy: 9.39\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 42 optimizer: stochastic\t lr: 1e-08\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 9.43\n",
      "\tEpoch 2 Accuracy: 9.43\n",
      "\tNo accuracy change 9.43 == 9.43\n",
      "accuracy: 9.43\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 43 optimizer: Adam\t lr: 0.35\t #neurons: [256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 9.93\n",
      "\tEpoch 2 Accuracy: 9.93\n",
      "\tNo accuracy change 9.93 == 9.93\n",
      "accuracy: 9.93\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 44 optimizer: RMSprop\t lr: 1e-08\t #neurons: [256, 256, 256, 10]\n",
      "\tEpoch 1 Accuracy: 9.20\n",
      "\tEpoch 2 Accuracy: 9.20\n",
      "\tNo accuracy change 9.20 == 9.20\n",
      "accuracy: 9.20\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 45 optimizer: momentum\t lr: 0.0001\t #neurons: [512, 512, 10]\n",
      "\tEpoch 1 Accuracy: 4.12\n",
      "\tEpoch 2 Accuracy: 4.16\n",
      "\tEpoch 3 Accuracy: 4.28\n",
      "\tEpoch 4 Accuracy: 4.37\n",
      "\tEpoch 5 Accuracy: 4.48\n",
      "\tEpoch 6 Accuracy: 4.62\n",
      "\tEpoch 7 Accuracy: 4.72\n",
      "\tEpoch 8 Accuracy: 4.83\n",
      "\tEpoch 9 Accuracy: 4.92\n",
      "\tEpoch 10 Accuracy: 4.98\n",
      "\tEpoch 11 Accuracy: 5.04\n",
      "\tEpoch 12 Accuracy: 5.13\n",
      "\tEpoch 13 Accuracy: 5.17\n",
      "\tEpoch 14 Accuracy: 5.26\n",
      "\tEpoch 15 Accuracy: 5.33\n",
      "\tEpoch 16 Accuracy: 5.38\n",
      "\tEpoch 17 Accuracy: 5.44\n",
      "\tEpoch 18 Accuracy: 5.53\n",
      "\tEpoch 19 Accuracy: 5.60\n",
      "\tEpoch 20 Accuracy: 5.73\n",
      "\tEpoch 21 Accuracy: 5.78\n",
      "\tEpoch 22 Accuracy: 5.82\n",
      "\tEpoch 23 Accuracy: 5.88\n",
      "\tEpoch 24 Accuracy: 5.96\n",
      "\tEpoch 25 Accuracy: 6.01\n",
      "\tEpoch 26 Accuracy: 6.07\n",
      "\tEpoch 27 Accuracy: 6.21\n",
      "\tEpoch 28 Accuracy: 6.25\n",
      "\tEpoch 29 Accuracy: 6.37\n",
      "\tEpoch 30 Accuracy: 6.45\n",
      "accuracy: 6.45\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 46 optimizer: stochastic\t lr: 0.35\t #neurons: [256, 512, 48, 10]\n",
      "\tEpoch 1 Accuracy: 35.64\n",
      "\tEpoch 2 Accuracy: 51.49\n",
      "\tEpoch 3 Accuracy: 57.27\n",
      "\tEpoch 4 Accuracy: 62.16\n",
      "\tEpoch 5 Accuracy: 65.17\n",
      "\tEpoch 6 Accuracy: 65.83\n",
      "\tEpoch 7 Accuracy: 67.97\n",
      "\tEpoch 8 Accuracy: 68.57\n",
      "\tEpoch 9 Accuracy: 69.00\n",
      "\tEpoch 10 Accuracy: 70.19\n",
      "\tEpoch 11 Accuracy: 71.24\n",
      "\tEpoch 12 Accuracy: 71.49\n",
      "\tEpoch 13 Accuracy: 72.38\n",
      "\tEpoch 14 Accuracy: 71.67\n",
      "\tEpoch 15 Accuracy: 73.51\n",
      "\tEpoch 16 Accuracy: 73.13\n",
      "\tEpoch 17 Accuracy: 74.08\n",
      "\tEpoch 18 Accuracy: 73.99\n",
      "\tEpoch 19 Accuracy: 74.92\n",
      "\tEpoch 20 Accuracy: 75.07\n",
      "\tEpoch 21 Accuracy: 75.95\n",
      "\tEpoch 22 Accuracy: 75.65\n",
      "\tEpoch 23 Accuracy: 75.54\n",
      "\tEpoch 24 Accuracy: 76.12\n",
      "\tEpoch 25 Accuracy: 76.44\n",
      "\tEpoch 26 Accuracy: 76.53\n",
      "\tEpoch 27 Accuracy: 77.29\n",
      "\tEpoch 28 Accuracy: 77.67\n",
      "\tEpoch 29 Accuracy: 77.34\n",
      "\tEpoch 30 Accuracy: 77.78\n",
      "accuracy: 77.78\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 47 optimizer: RMSprop\t lr: 1e-06\t #neurons: [512, 512, 10]\n",
      "\tEpoch 1 Accuracy: 6.77\n",
      "\tEpoch 2 Accuracy: 6.91\n",
      "\tEpoch 3 Accuracy: 7.04\n",
      "\tEpoch 4 Accuracy: 7.12\n",
      "\tEpoch 5 Accuracy: 7.10\n",
      "\tEpoch 6 Accuracy: 7.12\n",
      "\tEpoch 7 Accuracy: 7.20\n",
      "\tEpoch 8 Accuracy: 7.26\n",
      "\tEpoch 9 Accuracy: 7.34\n",
      "\tEpoch 10 Accuracy: 7.44\n",
      "\tEpoch 11 Accuracy: 7.49\n",
      "\tEpoch 12 Accuracy: 7.58\n",
      "\tEpoch 13 Accuracy: 7.65\n",
      "\tEpoch 14 Accuracy: 7.73\n",
      "\tEpoch 15 Accuracy: 7.79\n",
      "\tEpoch 16 Accuracy: 7.85\n",
      "\tEpoch 17 Accuracy: 7.92\n",
      "\tEpoch 18 Accuracy: 7.98\n",
      "\tEpoch 19 Accuracy: 8.04\n",
      "\tEpoch 20 Accuracy: 8.06\n",
      "\tEpoch 21 Accuracy: 8.20\n",
      "\tEpoch 22 Accuracy: 8.27\n",
      "\tEpoch 23 Accuracy: 8.31\n",
      "\tEpoch 24 Accuracy: 8.37\n",
      "\tEpoch 25 Accuracy: 8.43\n",
      "\tEpoch 26 Accuracy: 8.45\n",
      "\tEpoch 27 Accuracy: 8.58\n",
      "\tEpoch 28 Accuracy: 8.62\n",
      "\tEpoch 29 Accuracy: 8.70\n",
      "\tEpoch 30 Accuracy: 8.77\n",
      "accuracy: 8.77\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 48 optimizer: momentum\t lr: 0.01\t #neurons: [256, 10]\n",
      "\tEpoch 1 Accuracy: 17.05\n",
      "\tEpoch 2 Accuracy: 25.54\n",
      "\tEpoch 3 Accuracy: 37.07\n",
      "\tEpoch 4 Accuracy: 46.96\n",
      "\tEpoch 5 Accuracy: 51.14\n",
      "\tEpoch 6 Accuracy: 53.81\n",
      "\tEpoch 7 Accuracy: 55.93\n",
      "\tEpoch 8 Accuracy: 57.26\n",
      "\tEpoch 9 Accuracy: 58.80\n",
      "\tEpoch 10 Accuracy: 60.32\n",
      "\tEpoch 11 Accuracy: 62.07\n",
      "\tEpoch 12 Accuracy: 63.33\n",
      "\tEpoch 13 Accuracy: 64.18\n",
      "\tEpoch 14 Accuracy: 64.73\n",
      "\tEpoch 15 Accuracy: 65.13\n",
      "\tEpoch 16 Accuracy: 65.62\n",
      "\tEpoch 17 Accuracy: 66.10\n",
      "\tEpoch 18 Accuracy: 66.56\n",
      "\tEpoch 19 Accuracy: 66.98\n",
      "\tEpoch 20 Accuracy: 67.36\n",
      "\tEpoch 21 Accuracy: 67.52\n",
      "\tEpoch 22 Accuracy: 67.88\n",
      "\tEpoch 23 Accuracy: 68.21\n",
      "\tEpoch 24 Accuracy: 68.58\n",
      "\tEpoch 25 Accuracy: 68.76\n",
      "\tEpoch 26 Accuracy: 68.94\n",
      "\tEpoch 27 Accuracy: 69.11\n",
      "\tEpoch 28 Accuracy: 69.41\n",
      "\tEpoch 29 Accuracy: 69.55\n",
      "\tEpoch 30 Accuracy: 69.74\n",
      "accuracy: 69.74\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "trial: 49 optimizer: momentum\t lr: 0.1\t #neurons: [256, 10]\n",
      "\tEpoch 1 Accuracy: 56.80\n",
      "\tEpoch 2 Accuracy: 65.83\n",
      "\tEpoch 3 Accuracy: 72.57\n",
      "\tEpoch 4 Accuracy: 75.78\n",
      "\tEpoch 5 Accuracy: 77.28\n",
      "\tEpoch 6 Accuracy: 78.10\n",
      "\tEpoch 7 Accuracy: 78.99\n",
      "\tEpoch 8 Accuracy: 79.56\n",
      "\tEpoch 9 Accuracy: 79.90\n",
      "\tEpoch 10 Accuracy: 80.22\n",
      "\tEpoch 11 Accuracy: 80.57\n",
      "\tEpoch 12 Accuracy: 81.06\n",
      "\tEpoch 13 Accuracy: 81.24\n",
      "\tEpoch 14 Accuracy: 81.35\n",
      "\tEpoch 15 Accuracy: 81.46\n",
      "\tEpoch 16 Accuracy: 81.60\n",
      "\tEpoch 17 Accuracy: 81.88\n",
      "\tEpoch 18 Accuracy: 82.09\n",
      "\tEpoch 19 Accuracy: 82.06\n",
      "\tEpoch 20 Accuracy: 82.09\n",
      "\tEpoch 21 Accuracy: 82.11\n",
      "\tEpoch 22 Accuracy: 82.25\n",
      "\tEpoch 23 Accuracy: 82.51\n",
      "\tEpoch 24 Accuracy: 82.54\n",
      "\tEpoch 25 Accuracy: 82.68\n",
      "\tEpoch 26 Accuracy: 82.76\n",
      "\tEpoch 27 Accuracy: 82.76\n",
      "\tNo accuracy change 82.76 == 82.76\n",
      "accuracy: 82.76\n",
      "\n",
      "accuracy: 84.03, optimizer: momentum, lr: 0.35, epoch 23, #neurons [256, 10]\n"
     ]
    }
   ],
   "source": [
    "optimizers = [\"stochastic\", \"momentum\", \"RMSprop\", \"Adam\"]\n",
    "learning_rates = [0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.14, 0.18, 0.2, 0.25, 0.3, 0.35]\n",
    "neurons = [[256, 10], [512, 10], [48, 48, 10], \n",
    "           [256, 48, 10], [48, 256, 10], [256, 256, 10], [512, 256, 10], [256, 512, 10], [512, 512, 10],\n",
    "            [48, 48, 48, 10], [256, 256, 256, 10], [256, 512, 48, 10]]\n",
    "\n",
    "tune_hyperparameters(optimizers=optimizers, learning_rates=learning_rates, neurons=neurons, epoch=30, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_output(mlp):\n",
    "    tot = 0\n",
    "    wrong = 0\n",
    "    right = 0\n",
    "\n",
    "    for test_x, test_y in test_dataloader:\n",
    "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "\n",
    "        test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "\n",
    "        output = mlp(test_x_flattened)\n",
    "        \n",
    "        for pred, act, img in zip(output, test_y, test_x):\n",
    "            pred_index = torch.argmax(pred).item()\n",
    "            act_index = act.item()\n",
    "\n",
    "            print(f\"Predicted: {labels_map[pred_index]}, Number: {torch.max(output).item()}\")\n",
    "            print(f\"Target: {labels_map[act_index]}, Number: {act.item()}\")\n",
    "            img = img.cpu()\n",
    "            plt.imshow(img[0], cmap=\"grey\")\n",
    "            plt.show()\n",
    "\n",
    "            if pred_index == act_index:\n",
    "                print(\"WRONG\")\n",
    "                right += 1\n",
    "            else: \n",
    "                print(\"WRONG\")\n",
    "                wrong += 1\n",
    "\n",
    "            tot += 1\n",
    "\n",
    "    right_ratio = right / tot * 100\n",
    "    print(f\"Test Accuracy: {right_ratio}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(784, [256, 10], lr=0.35, optimizer=\"momentum\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------------\n",
      "Loss: 2.289247\t [   64/59968]\n",
      "Loss: 2.066873\t [12864/59968]\n",
      "Loss: 2.074296\t [25664/59968]\n",
      "Loss: 2.078497\t [38464/59968]\n",
      "Accuracy: 68.70833333333334\n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------------\n",
      "Loss: 2.036775\t [   64/59968]\n",
      "Loss: 2.029747\t [12864/59968]\n",
      "Loss: 2.042033\t [25664/59968]\n",
      "Loss: 2.056252\t [38464/59968]\n",
      "Accuracy: 76.74166666666666\n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------------\n",
      "Loss: 2.031684\t [   64/59968]\n",
      "Loss: 2.019283\t [12864/59968]\n",
      "Loss: 2.041508\t [25664/59968]\n",
      "Loss: 2.027444\t [38464/59968]\n",
      "Accuracy: 78.55\n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------------\n",
      "Loss: 2.021722\t [   64/59968]\n",
      "Loss: 2.012462\t [12864/59968]\n",
      "Loss: 2.033803\t [25664/59968]\n",
      "Loss: 2.035491\t [38464/59968]\n",
      "Accuracy: 79.45\n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------------\n",
      "Loss: 2.011530\t [   64/59968]\n",
      "Loss: 2.008320\t [12864/59968]\n",
      "Loss: 2.029813\t [25664/59968]\n",
      "Loss: 2.025535\t [38464/59968]\n",
      "Accuracy: 79.23333333333333\n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------------\n",
      "Loss: 2.005877\t [   64/59968]\n",
      "Loss: 2.014796\t [12864/59968]\n",
      "Loss: 2.019821\t [25664/59968]\n",
      "Loss: 2.014768\t [38464/59968]\n",
      "Accuracy: 80.5\n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------------\n",
      "Loss: 2.000523\t [   64/59968]\n",
      "Loss: 2.016752\t [12864/59968]\n",
      "Loss: 2.024513\t [25664/59968]\n",
      "Loss: 2.025115\t [38464/59968]\n",
      "Accuracy: 81.325\n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------------\n",
      "Loss: 2.005878\t [   64/59968]\n",
      "Loss: 2.002239\t [12864/59968]\n",
      "Loss: 2.015445\t [25664/59968]\n",
      "Loss: 2.019314\t [38464/59968]\n",
      "Accuracy: 81.03333333333333\n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------------\n",
      "Loss: 2.004861\t [   64/59968]\n",
      "Loss: 1.994783\t [12864/59968]\n",
      "Loss: 2.024339\t [25664/59968]\n",
      "Loss: 2.019093\t [38464/59968]\n",
      "Accuracy: 81.94166666666666\n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------------\n",
      "Loss: 2.002511\t [   64/59968]\n",
      "Loss: 1.994898\t [12864/59968]\n",
      "Loss: 2.011965\t [25664/59968]\n",
      "Loss: 2.027980\t [38464/59968]\n",
      "Accuracy: 81.45833333333333\n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------------\n",
      "Loss: 2.003063\t [   64/59968]\n",
      "Loss: 1.992789\t [12864/59968]\n",
      "Loss: 2.017953\t [25664/59968]\n",
      "Loss: 2.016424\t [38464/59968]\n",
      "Accuracy: 81.61666666666667\n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------------\n",
      "Loss: 2.012282\t [   64/59968]\n",
      "Loss: 1.989552\t [12864/59968]\n",
      "Loss: 2.017044\t [25664/59968]\n",
      "Loss: 2.005900\t [38464/59968]\n",
      "Accuracy: 82.04166666666667\n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------------\n",
      "Loss: 2.005096\t [   64/59968]\n",
      "Loss: 1.990607\t [12864/59968]\n",
      "Loss: 2.011356\t [25664/59968]\n",
      "Loss: 2.024204\t [38464/59968]\n",
      "Accuracy: 82.65\n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------------\n",
      "Loss: 1.997009\t [   64/59968]\n",
      "Loss: 2.001694\t [12864/59968]\n",
      "Loss: 2.019530\t [25664/59968]\n",
      "Loss: 2.014087\t [38464/59968]\n",
      "Accuracy: 82.55833333333334\n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------------\n",
      "Loss: 2.001150\t [   64/59968]\n",
      "Loss: 1.998481\t [12864/59968]\n",
      "Loss: 2.015110\t [25664/59968]\n",
      "Loss: 2.006168\t [38464/59968]\n",
      "Accuracy: 82.69166666666666\n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------------\n",
      "Loss: 1.999153\t [   64/59968]\n",
      "Loss: 1.997889\t [12864/59968]\n",
      "Loss: 2.015737\t [25664/59968]\n",
      "Loss: 2.012335\t [38464/59968]\n",
      "Accuracy: 83.00833333333333\n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------------\n",
      "Loss: 2.010329\t [   64/59968]\n",
      "Loss: 1.999676\t [12864/59968]\n",
      "Loss: 2.016366\t [25664/59968]\n",
      "Loss: 2.014388\t [38464/59968]\n",
      "Accuracy: 82.20833333333334\n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------------\n",
      "Loss: 2.003385\t [   64/59968]\n",
      "Loss: 1.995408\t [12864/59968]\n",
      "Loss: 2.009882\t [25664/59968]\n",
      "Loss: 2.012330\t [38464/59968]\n",
      "Accuracy: 82.64166666666667\n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------------\n",
      "Loss: 1.988557\t [   64/59968]\n",
      "Loss: 1.995281\t [12864/59968]\n",
      "Loss: 2.021415\t [25664/59968]\n",
      "Loss: 2.016095\t [38464/59968]\n",
      "Accuracy: 83.35833333333333\n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------------\n",
      "Loss: 1.996583\t [   64/59968]\n",
      "Loss: 1.992249\t [12864/59968]\n",
      "Loss: 2.022931\t [25664/59968]\n",
      "Loss: 2.009185\t [38464/59968]\n",
      "Accuracy: 82.88333333333333\n",
      "\n",
      "Epoch 21\n",
      "-----------------------------------------\n",
      "Loss: 1.994446\t [   64/59968]\n",
      "Loss: 1.994769\t [12864/59968]\n",
      "Loss: 2.004721\t [25664/59968]\n",
      "Loss: 2.023715\t [38464/59968]\n",
      "Accuracy: 83.29166666666666\n",
      "\n",
      "Epoch 22\n",
      "-----------------------------------------\n",
      "Loss: 1.982108\t [   64/59968]\n",
      "Loss: 1.998428\t [12864/59968]\n",
      "Loss: 2.010920\t [25664/59968]\n",
      "Loss: 2.011829\t [38464/59968]\n",
      "Accuracy: 83.575\n",
      "\n",
      "Epoch 23\n",
      "-----------------------------------------\n",
      "Loss: 1.991139\t [   64/59968]\n",
      "Loss: 1.998560\t [12864/59968]\n",
      "Loss: 2.015497\t [25664/59968]\n",
      "Loss: 2.011638\t [38464/59968]\n",
      "Accuracy: 83.64166666666667\n",
      "\n",
      "Epoch 24\n",
      "-----------------------------------------\n",
      "Loss: 1.989461\t [   64/59968]\n",
      "Loss: 1.996100\t [12864/59968]\n",
      "Loss: 2.011552\t [25664/59968]\n",
      "Loss: 2.009592\t [38464/59968]\n",
      "Accuracy: 83.3\n",
      "\n",
      "Epoch 25\n",
      "-----------------------------------------\n",
      "Loss: 1.996660\t [   64/59968]\n",
      "Loss: 1.989386\t [12864/59968]\n",
      "Loss: 2.010051\t [25664/59968]\n",
      "Loss: 2.018933\t [38464/59968]\n",
      "Accuracy: 83.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print(f\"Epoch {i + 1}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    train(mlp, loss_fn)\n",
    "    print(f\"Accuracy: {validate(mlp)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
