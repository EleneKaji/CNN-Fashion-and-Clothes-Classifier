{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split # loads data either in chunks or full\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets # open datasets\n",
    "from torchvision.transforms import ToTensor # transfor data to tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing gpu for training\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training and test data from open datasets.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train_size = int(len(train_data) * 0.8)  # 80% of the data for training\n",
    "val_size = len(train_data) - train_size  # 20% of the data for validation\n",
    "train_subset, val_subset = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_subset, batch_size=64) \n",
    "val_dataloader = DataLoader(val_subset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Coat, Number: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting and understanding images and labels with first batch\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "idx = torch.randint(0, 64, (1,)).item()\n",
    "image = images[idx].squeeze()\n",
    "label = labels[idx]\n",
    "print(f\"Name: {labels_map[label.item()]}, Number: {label.item()}\")\n",
    "plt.imshow(image, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn((64, 1, 28, 28))\n",
    "w1 = torch.randn((12, 1, 2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12, 27, 27])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv(input, w, stride=1, padding=0):\n",
    "    batch_size, in_channels, in_height, in_width = input.shape\n",
    "    out_channels, _, kernel_height, kernel_width = w.shape\n",
    "\n",
    "    out_height = (in_height - kernel_height + 2 * padding) // stride + 1\n",
    "    out_width = (in_width - kernel_width + 2 * padding) // stride + 1\n",
    "\n",
    "    unfolded_input = torch.zeros(batch_size, out_height, out_width, in_channels * kernel_height * kernel_width, device=\"cuda:0\") # [64, 27, 27, 4]\n",
    "\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            start_i = i * stride\n",
    "            end_i = start_i + kernel_height\n",
    "            start_j = j * stride\n",
    "            end_j = start_j + kernel_width\n",
    "\n",
    "            patch = input[:, :, start_i:end_i, start_j:end_j]\n",
    "            patch = patch.reshape(batch_size, -1)\n",
    "            \n",
    "            unfolded_input[:, i, j, :] = patch\n",
    "    \n",
    "    unfolded_input = unfolded_input.view(batch_size * out_height * out_width, in_channels * kernel_height * kernel_width)\n",
    "    unfolded_kernel = w.view(out_channels, -1).t()\n",
    "    \n",
    "    unfolded_output = torch.matmul(unfolded_input, unfolded_kernel)# [64 * 27 * 27, 12]\n",
    "    output = unfolded_output.view(batch_size, out_height, out_width, out_channels) # [64, 27, 27, 12]\n",
    "    output = output.permute(0, 3, 1, 2).contiguous()\n",
    "    return output\n",
    "\n",
    "\n",
    "input1 = torch.randn((64, 1, 28, 28), device=\"cuda:0\")\n",
    "w1 = torch.randn((12, 1, 2, 2), device=\"cuda:0\")\n",
    "stride = 1 \n",
    "padding = 0 \n",
    "\n",
    "output = conv(input1, w1, stride=stride, padding=padding)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, parameters, lr, name):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "        self.name = name\n",
    "\n",
    "        self.momentum = 0.9\n",
    "        self.velocities = [torch.zeros_like(p) for p in parameters]\n",
    "\n",
    "        self.decay_rate = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.sq_grads = [torch.zeros_like(p) for p in parameters]\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.m_t = [torch.zeros_like(p) for p in parameters]\n",
    "        self.v_t = [torch.zeros_like(p) for p in parameters]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        if self.name == \"stochastic\":\n",
    "            self.stochastic_step()\n",
    "        elif self.name == \"momentum\":\n",
    "            self.momentum_step()\n",
    "        elif self.name == \"RMSprop\":\n",
    "            self.RMSprop_step()\n",
    "        elif self.name == \"Adam\":\n",
    "            self.Adam_step()\n",
    "        else:\n",
    "            print(\"no valid optimizer with such name\")\n",
    "\n",
    "    def stochastic_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                if param is not None:\n",
    "                    param -= param.grad * self.lr\n",
    "                    # param.grad.zero_()\n",
    "\n",
    "    def momentum_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param, velocity in zip(self.parameters, self.velocities):\n",
    "                if param is not None:\n",
    "                    # view momentum as the mass that scales the last velocity a bit but still gives more direction\n",
    "                    # the rest is just the stochatic gradient descent\n",
    "                    velocity.mul_(self.momentum).add_(param.grad, alpha=self.lr)\n",
    "                    param.sub_(velocity)\n",
    "                    # param.grad.zero_()\n",
    "\n",
    "                    # another way\n",
    "                    # higher the momentum closer it pays attention to the upcoming points\n",
    "                    # lower the momentum closer it pays attention to the previous points\n",
    "                    # velocity.mul_(self.momentum).add_(param.grad, alpha=(1 - self.momentum))\n",
    "                    # param.sub_(velocity, alpha=self.lr)\n",
    "                    # param.grad.zero_()\n",
    "    \n",
    "    def RMSprop_step(self):\n",
    "        with torch.no_grad():\n",
    "            for param, sq_grad in zip(self.parameters, self.sq_grads):\n",
    "                if param.grad is not None:\n",
    "                    sq_grad.mul_(self.decay_rate).addcmul_(param.grad, param.grad, value=1 - self.decay_rate)\n",
    "                    sqrt = sq_grad.sqrt().add(self.epsilon)\n",
    "                    adjusted_grad = param.grad / sqrt\n",
    "                    param.sub_(adjusted_grad, alpha=self.lr)\n",
    "\n",
    "    def Adam_step(self):\n",
    "        with torch.no_grad():\n",
    "            self.t += 1\n",
    "            for param, m, v in zip(self.parameters, self.m_t, self.v_t):\n",
    "                if param is not None:\n",
    "                    m.mul_(self.beta1).add_(param.grad, alpha=1 - self.beta1)\n",
    "                    v.mul_(self.beta2).addcmul_(param.grad, param.grad, value=1 - self.beta2)\n",
    "                    m_hat = m / (1 - self.beta1 ** self.t)\n",
    "                    v_hat = v / (1 - self.beta2 ** self.t)\n",
    "                    param.sub_(m_hat / (v_hat.sqrt().add(self.epsilon)), alpha=self.lr)\n",
    "\n",
    "    def zero_grads(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                if param.grad is not None:\n",
    "                    param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: \n",
    "    # nin is the number of input (prev layer)\n",
    "    # nout is the number of output (next layer)\n",
    "    def __init__(self, nin, nout, processor=\"cuda:0\"):\n",
    "        self.w = torch.randn((nin, nout), requires_grad=True, device=processor)\n",
    "        self.b = torch.randn(1, requires_grad=True, device=processor)\n",
    "    \n",
    "    # x is the input in (batch, input)\n",
    "    def __call__(self, x):\n",
    "        eq = torch.matmul(x, self.w) + self.b\n",
    "        out = torch.tanh(eq)\n",
    "        return out # returns (batch, output # of neurons for next layer)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts, lr, optimizer=\"stochastic\", processor=\"cuda:0\"):\n",
    "        self.lr = lr\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "        self.optimizer = Optimizer(self.parameters(), lr, optimizer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grads(self):\n",
    "        self.optimizer.zero_grads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mlp, loss_fn):\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "        x_flattened = x.view(x.size(0), -1)\n",
    "\n",
    "        output = mlp(x_flattened)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        mlp.zero_grads()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        mlp.update_parameters()\n",
    "\n",
    "        if batch % 200 == 0:\n",
    "            print(f\"Loss: {loss:>7f}\\t [{((batch + 1) * 64):>5d}/{937 * 64}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(mlp):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dataloader:\n",
    "            x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "            x_falttened = x.view(x.size(0), -1)\n",
    "            output = mlp(x_falttened)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            tot += y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mlp):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in test_dataloader:\n",
    "            test_x, test_y = test_x.to(\"cuda:0\"), test_y.to(\"cuda:0\")\n",
    "\n",
    "            test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "            output = mlp(test_x_flattened)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(test_y.view_as(pred)).sum().item()\n",
    "            tot += test_y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(optimizers, learning_rates, neurons, epoch, num_trials):\n",
    "    best_accuracy = 0.0\n",
    "    best_optimizer = \"\"\n",
    "    best_lr = 0.0\n",
    "    best_epochs = 0\n",
    "    best_neurons = []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        optimizer = random.choice(optimizers)\n",
    "        lr = random.choice(learning_rates)\n",
    "        neuron = random.choice(neurons)\n",
    "                    \n",
    "        mlp = MLP(784, neuron, lr=lr, optimizer=optimizer)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"------------------------------------------------------------------------------------\")\n",
    "        print(f\"trial: {trial} optimizer: {optimizer}\\t lr: {lr}\\t #neurons: {neuron}\")\n",
    "\n",
    "        new_accuracy = 0.0\n",
    "        prev_accuracy = -1\n",
    "\n",
    "        for i in range(epoch):\n",
    "            if prev_accuracy == new_accuracy:\n",
    "                print(f\"\\tNo accuracy change {prev_accuracy:.2f} == {new_accuracy:.2f}\")\n",
    "                break\n",
    "            prev_accuracy = new_accuracy\n",
    "            train(mlp, loss_fn)\n",
    "            new_accuracy = validate(mlp)\n",
    "            print(f\"\\tEpoch {i + 1} Accuracy: {new_accuracy:.2f}\")\n",
    "\n",
    "            if new_accuracy > best_accuracy:\n",
    "                best_accuracy = new_accuracy\n",
    "                best_optimizer = optimizer\n",
    "                best_lr = lr\n",
    "                best_epochs = i + 1\n",
    "                best_neurons = neuron\n",
    "        \n",
    "        print(f\"accuracy: {new_accuracy:.2f}\\n\")\n",
    "\n",
    "    print(f\"accuracy: {best_accuracy:.2f}, optimizer: {best_optimizer}, lr: {best_lr}, epoch {best_epochs}, #neurons {best_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers = [\"stochastic\", \"momentum\", \"RMSprop\", \"Adam\"]\n",
    "# learning_rates = [0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.14, 0.18, 0.2, 0.25, 0.3, 0.35]\n",
    "# neurons = [[256, 10], [512, 10], [48, 48, 10], \n",
    "#            [256, 48, 10], [48, 256, 10], [256, 256, 10], [512, 256, 10], [256, 512, 10], [512, 512, 10],\n",
    "#             [48, 48, 48, 10], [256, 256, 256, 10], [256, 512, 48, 10]]\n",
    "\n",
    "# tune_hyperparameters(optimizers=optimizers, learning_rates=learning_rates, neurons=neurons, epoch=30, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_output(mlp):\n",
    "    tot = 0\n",
    "    wrong = 0\n",
    "    right = 0\n",
    "\n",
    "    for test_x, test_y in test_dataloader:\n",
    "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "\n",
    "        test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "\n",
    "        output = mlp(test_x_flattened)\n",
    "        \n",
    "        for pred, act, img in zip(output, test_y, test_x):\n",
    "            pred_index = torch.argmax(pred).item()\n",
    "            act_index = act.item()\n",
    "\n",
    "            print(f\"Predicted: {labels_map[pred_index]}, Number: {torch.max(output).item()}\")\n",
    "            print(f\"Target: {labels_map[act_index]}, Number: {act.item()}\")\n",
    "            img = img.cpu()\n",
    "            plt.imshow(img[0], cmap=\"grey\")\n",
    "            plt.show()\n",
    "\n",
    "            if pred_index == act_index:\n",
    "                print(\"WRONG\")\n",
    "                right += 1\n",
    "            else: \n",
    "                print(\"WRONG\")\n",
    "                wrong += 1\n",
    "\n",
    "            tot += 1\n",
    "\n",
    "    right_ratio = right / tot * 100\n",
    "    print(f\"Test Accuracy: {right_ratio}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(784, [64, 32, 10], lr=0.001, optimizer=\"Adam\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------------\n",
      "Loss: 2.290972\t [   64/59968]\n",
      "Loss: 2.176579\t [12864/59968]\n",
      "Loss: 2.135445\t [25664/59968]\n",
      "Loss: 2.123652\t [38464/59968]\n",
      "Accuracy: 63.075\n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------------\n",
      "Loss: 2.097186\t [   64/59968]\n",
      "Loss: 2.107466\t [12864/59968]\n",
      "Loss: 2.085687\t [25664/59968]\n",
      "Loss: 2.077597\t [38464/59968]\n",
      "Accuracy: 70.45\n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------------\n",
      "Loss: 2.061342\t [   64/59968]\n",
      "Loss: 2.081043\t [12864/59968]\n",
      "Loss: 2.067410\t [25664/59968]\n",
      "Loss: 2.057354\t [38464/59968]\n",
      "Accuracy: 73.80833333333334\n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------------\n",
      "Loss: 2.074096\t [   64/59968]\n",
      "Loss: 2.077935\t [12864/59968]\n",
      "Loss: 2.059581\t [25664/59968]\n",
      "Loss: 2.065313\t [38464/59968]\n",
      "Accuracy: 75.96666666666667\n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------------\n",
      "Loss: 2.051621\t [   64/59968]\n",
      "Loss: 2.081918\t [12864/59968]\n",
      "Loss: 2.055771\t [25664/59968]\n",
      "Loss: 2.052038\t [38464/59968]\n",
      "Accuracy: 77.34166666666667\n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------------\n",
      "Loss: 2.053256\t [   64/59968]\n",
      "Loss: 2.072323\t [12864/59968]\n",
      "Loss: 2.054409\t [25664/59968]\n",
      "Loss: 2.051493\t [38464/59968]\n",
      "Accuracy: 78.64999999999999\n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------------\n",
      "Loss: 2.043747\t [   64/59968]\n",
      "Loss: 2.064398\t [12864/59968]\n",
      "Loss: 2.045498\t [25664/59968]\n",
      "Loss: 2.050402\t [38464/59968]\n",
      "Accuracy: 79.025\n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------------\n",
      "Loss: 2.030407\t [   64/59968]\n",
      "Loss: 2.059002\t [12864/59968]\n",
      "Loss: 2.043290\t [25664/59968]\n",
      "Loss: 2.050588\t [38464/59968]\n",
      "Accuracy: 79.63333333333334\n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------------\n",
      "Loss: 2.034128\t [   64/59968]\n",
      "Loss: 2.059767\t [12864/59968]\n",
      "Loss: 2.047036\t [25664/59968]\n",
      "Loss: 2.038924\t [38464/59968]\n",
      "Accuracy: 80.36666666666666\n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------------\n",
      "Loss: 2.035856\t [   64/59968]\n",
      "Loss: 2.061421\t [12864/59968]\n",
      "Loss: 2.040183\t [25664/59968]\n",
      "Loss: 2.041569\t [38464/59968]\n",
      "Accuracy: 80.76666666666667\n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------------\n",
      "Loss: 2.036297\t [   64/59968]\n",
      "Loss: 2.058349\t [12864/59968]\n",
      "Loss: 2.040562\t [25664/59968]\n",
      "Loss: 2.028894\t [38464/59968]\n",
      "Accuracy: 80.79166666666666\n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------------\n",
      "Loss: 2.030046\t [   64/59968]\n",
      "Loss: 2.059587\t [12864/59968]\n",
      "Loss: 2.032226\t [25664/59968]\n",
      "Loss: 2.036324\t [38464/59968]\n",
      "Accuracy: 81.41666666666667\n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------------\n",
      "Loss: 2.029791\t [   64/59968]\n",
      "Loss: 2.065289\t [12864/59968]\n",
      "Loss: 2.024398\t [25664/59968]\n",
      "Loss: 2.030515\t [38464/59968]\n",
      "Accuracy: 81.03333333333333\n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------------\n",
      "Loss: 2.039719\t [   64/59968]\n",
      "Loss: 2.060816\t [12864/59968]\n",
      "Loss: 2.028903\t [25664/59968]\n",
      "Loss: 2.023531\t [38464/59968]\n",
      "Accuracy: 81.70833333333334\n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------------\n",
      "Loss: 2.023755\t [   64/59968]\n",
      "Loss: 2.058963\t [12864/59968]\n",
      "Loss: 2.033213\t [25664/59968]\n",
      "Loss: 2.022538\t [38464/59968]\n",
      "Accuracy: 81.58333333333333\n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------------\n",
      "Loss: 2.026184\t [   64/59968]\n",
      "Loss: 2.049011\t [12864/59968]\n",
      "Loss: 2.029805\t [25664/59968]\n",
      "Loss: 2.028168\t [38464/59968]\n",
      "Accuracy: 81.71666666666667\n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------------\n",
      "Loss: 2.022475\t [   64/59968]\n",
      "Loss: 2.043478\t [12864/59968]\n",
      "Loss: 2.027834\t [25664/59968]\n",
      "Loss: 2.026553\t [38464/59968]\n",
      "Accuracy: 82.06666666666666\n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------------\n",
      "Loss: 2.029770\t [   64/59968]\n",
      "Loss: 2.046941\t [12864/59968]\n",
      "Loss: 2.025523\t [25664/59968]\n",
      "Loss: 2.020752\t [38464/59968]\n",
      "Accuracy: 82.35\n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------------\n",
      "Loss: 2.034549\t [   64/59968]\n",
      "Loss: 2.041156\t [12864/59968]\n",
      "Loss: 2.031292\t [25664/59968]\n",
      "Loss: 2.030378\t [38464/59968]\n",
      "Accuracy: 82.65\n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------------\n",
      "Loss: 2.024971\t [   64/59968]\n",
      "Loss: 2.040840\t [12864/59968]\n",
      "Loss: 2.028260\t [25664/59968]\n",
      "Loss: 2.022009\t [38464/59968]\n",
      "Accuracy: 82.65\n",
      "\n",
      "Epoch 21\n",
      "-----------------------------------------\n",
      "Loss: 2.027768\t [   64/59968]\n",
      "Loss: 2.046950\t [12864/59968]\n",
      "Loss: 2.022043\t [25664/59968]\n",
      "Loss: 2.022019\t [38464/59968]\n",
      "Accuracy: 82.80833333333332\n",
      "\n",
      "Epoch 22\n",
      "-----------------------------------------\n",
      "Loss: 2.026579\t [   64/59968]\n",
      "Loss: 2.037474\t [12864/59968]\n",
      "Loss: 2.021172\t [25664/59968]\n",
      "Loss: 2.024773\t [38464/59968]\n",
      "Accuracy: 82.93333333333334\n",
      "\n",
      "Epoch 23\n",
      "-----------------------------------------\n",
      "Loss: 2.023296\t [   64/59968]\n",
      "Loss: 2.035092\t [12864/59968]\n",
      "Loss: 2.017516\t [25664/59968]\n",
      "Loss: 2.016890\t [38464/59968]\n",
      "Accuracy: 83.03333333333333\n",
      "\n",
      "Epoch 24\n",
      "-----------------------------------------\n",
      "Loss: 2.023770\t [   64/59968]\n",
      "Loss: 2.034439\t [12864/59968]\n",
      "Loss: 2.015724\t [25664/59968]\n",
      "Loss: 2.023800\t [38464/59968]\n",
      "Accuracy: 83.22500000000001\n",
      "\n",
      "Epoch 25\n",
      "-----------------------------------------\n",
      "Loss: 2.028183\t [   64/59968]\n",
      "Loss: 2.037021\t [12864/59968]\n",
      "Loss: 2.020671\t [25664/59968]\n",
      "Loss: 2.020144\t [38464/59968]\n",
      "Accuracy: 83.09166666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print(f\"Epoch {i + 1}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    train(mlp, loss_fn)\n",
    "    print(f\"Accuracy: {validate(mlp)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.77%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
