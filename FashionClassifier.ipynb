{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader # loads data either in chunks or full\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets # open datasets\n",
    "from torchvision.transforms import ToTensor # transfor data to tensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing gpu for training\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training and test data from open datasets.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train_dataloader = DataLoader(train_data, batch_size=64) # goes over 938 batches of 64\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Sneaker, Number: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting and understanding images and labels with first batch\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "idx = torch.randint(0, 64, (1,)).item()\n",
    "image = images[idx].squeeze()\n",
    "label = labels[idx]\n",
    "print(f\"Name: {labels_map[label.item()]}, Number: {label.item()}\")\n",
    "plt.imshow(image, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (images): torch.Size([64, 784])\t Output (labels): torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# flattening the image from 2d to 1d\n",
    "images = images.view(images.size(0), -1)\n",
    "print(f\"Input (images): {images.shape}\\t Output (labels): {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing MLP\n",
    "\n",
    "class Neuron:\n",
    "    # nin is number of inputs\n",
    "    def __init__(self, nin):\n",
    "        self.w = torch.rand(nin, requires_grad=True, device=\"cuda:0\")\n",
    "        self.b = torch.randn(1, requires_grad=True, device=\"cuda:0\")\n",
    "    \n",
    "    # x is how many inputs\n",
    "    def __call__(self, x):\n",
    "        x = torch.as_tensor(x).clone().detach().requires_grad_(True).float() # clone tensor \n",
    "        act = torch.matmul(self.w, x) + self.b  # matrix multiplication with compatible shapes\n",
    "        out = torch.tanh(act)\n",
    "        return out # tensor of 1D with 1 value\n",
    "    \n",
    "    def parameters(self):\n",
    "        return torch.cat([self.w, self.b]).requires_grad_()\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, nin, nout):\n",
    "        # create nout neurons with nin inputs\n",
    "        # the amount of neurons is based on how many outputs we need\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)] # list of neurons\n",
    "    \n",
    "    # x is how many neurons\n",
    "    def __call__(self, x):\n",
    "        x = torch.as_tensor(x).cuda().clone().detach().requires_grad_(True).float()\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        # print(self.layers[0].parameters())\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP:\n",
    "    # nin is number of inputs\n",
    "    # nouts is the list of number of outputs/neurons per each layer\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "    \n",
    "    # bruh this is forward propagation?? weird\n",
    "    def __call__(self, x):\n",
    "        x = torch.as_tensor(x).cuda().clone().detach().requires_grad_(True).float()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) # x is the input from the other neurons\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000], device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing neuron\n",
    "neuron = Neuron(784)\n",
    "random_tensor = torch.randn(784, dtype=torch.float32, device=device)\n",
    "neuron(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-0.9697], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([-0.9331], device='cuda:0', grad_fn=<TanhBackward0>)]"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing layer\n",
    "layer = Layer(784, 10)\n",
    "layer(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000], device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP(784, [16, 16, 1])\n",
    "mlp(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device)\n",
    "labels = labels / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elene2004\\AppData\\Local\\Temp\\ipykernel_5620\\2361245539.py:16: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  if p.grad is not None:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([26.8493], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = [mlp(img) for img in images]\n",
    "# ypred\n",
    "# stacked_tensor = torch.stack(ypred)\n",
    "# stacked_tensor\n",
    "# print(stacked_tensor)\n",
    "# print(labels)\n",
    "\n",
    "loss = sum([(yout - ygt) ** 2 for ygt, yout in zip(labels, ypred)])\n",
    "# # [print(l.requires_grad) for l in mlp.parameters()]\n",
    "\n",
    "# # for l in mlp.parameters():\n",
    "# #     if l.requires_grad is not True:\n",
    "# #         print(\"boohoo\")\n",
    "# # Zero out gradients\n",
    "for p in mlp.parameters():\n",
    "    if p.grad is not None:\n",
    "        p.grad.zero_()  # Zero out gradients for each parameter\n",
    "\n",
    "# Backpropagation\n",
    "ypred.backward(retain_graph=True)\n",
    "\n",
    "# Update parameters using gradient descent\n",
    "learning_rate = 0.5\n",
    "with torch.no_grad():  # Disable gradient tracking for parameter update\n",
    "    for p in mlp.parameters():\n",
    "        if p.grad is not None:  # Check if gradient is not None\n",
    "            p.data += learning_rate * p.grad # Update parameters using gradient descent\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for batch, (x, y) in enumerate(train_dataloader):\n",
    "#     x = x.view(x.size(0), -1)\n",
    "\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "\n",
    "#     for img in x:\n",
    "#         # img.to(device)\n",
    "#         # print(img.shape)\n",
    "#         mlp(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
