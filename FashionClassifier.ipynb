{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4762,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader # loads data either in chunks or full\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets # open datasets\n",
    "from torchvision.transforms import ToTensor # transfor data to tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 4763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing gpu for training\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training and test data from open datasets.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train_dataloader = DataLoader(train_data, batch_size=64) # goes over 938 batches of 64\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Sandal, Number: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting and understanding images and labels with first batch\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "idx = torch.randint(0, 64, (1,)).item()\n",
    "image = images[idx].squeeze()\n",
    "label = labels[idx]\n",
    "print(f\"Name: {labels_map[label.item()]}, Number: {label.item()}\")\n",
    "plt.imshow(image, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4767,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_train_data_x = []\n",
    "# processed_train_data_y = []\n",
    "\n",
    "# for batch, (x, y) in enumerate(train_dataloader):\n",
    "#     x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "#     for xi, yi in zip(x, y):\n",
    "#         flattened_xi = torch.flatten(xi)\n",
    "#         processed_train_data_x.append(flattened_xi)\n",
    "#         processed_train_data_y.append(yi)\n",
    "\n",
    "# stacked_train_data_x = torch.stack(processed_train_data_x, dim=0)\n",
    "# stacked_train_data_y = torch.tensor(processed_train_data_y)\n",
    "\n",
    "# print(\"Shape of stacked_train_data_x:\", stacked_train_data_x.shape)\n",
    "# print(\"Shape of stacked_train_data_y:\", stacked_train_data_y.shape)\n",
    "\n",
    "# stacked_train_data_x = stacked_train_data_x.to(device)\n",
    "# stacked_train_data_y = stacked_train_data_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4768,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn((64, 784), device=device)\n",
    "output1 = torch.randn((64, 10), device=device)\n",
    "# w1 = torch.randn((784, 12))\n",
    "# b1 = torch.randn((1,))\n",
    "\n",
    "# output1 = torch.matmul(input1, w1) + b1\n",
    "# output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4769,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: \n",
    "    # nin is the number of input (prev layer)\n",
    "    # nout is the number of output (next layer)\n",
    "    def __init__(self, nin, nout, processor=\"cuda:0\"):\n",
    "        self.w = torch.randn((nin, nout), requires_grad=True, device=processor)\n",
    "        self.b = torch.randn(1, requires_grad=True, device=processor)\n",
    "    \n",
    "    # x is the input in (batch, input)\n",
    "    def __call__(self, x):\n",
    "        eq = torch.matmul(x, self.w) + self.b\n",
    "        out = torch.tanh(eq)\n",
    "        return out # returns (batch, output # of neurons for next layer)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts, lr, processor=\"cuda:0\"):\n",
    "        self.lr = lr\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters():\n",
    "                if param is not None:\n",
    "                    param -= param.grad * self.lr\n",
    "                    param.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4770,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mlp):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for test_x, test_y in test_dataloader:\n",
    "            test_x, test_y = test_x.to(\"cuda:0\"), test_y.to(\"cuda:0\")\n",
    "\n",
    "            test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "            output = mlp(test_x_flattened)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(test_y.view_as(pred)).sum().item()\n",
    "            tot += test_y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4771,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(mlp):\n",
    "    tot = 0\n",
    "    wrong = 0\n",
    "    right = 0\n",
    "\n",
    "    for test_x, test_y in test_dataloader:\n",
    "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "\n",
    "        test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "\n",
    "        output = mlp(test_x_flattened)\n",
    "        \n",
    "        for pred, act, img in zip(output, test_y, test_x):\n",
    "            pred_index = torch.argmax(pred).item()\n",
    "            act_index = act.item()\n",
    "\n",
    "            print(f\"Predicted: {labels_map[pred_index]}, Number: {torch.max(output).item()}\")\n",
    "            print(f\"Target: {labels_map[act_index]}, Number: {act.item()}\")\n",
    "            img = img.cpu()\n",
    "            plt.imshow(img[0], cmap=\"grey\")\n",
    "            plt.show()\n",
    "\n",
    "            if pred_index == act_index:\n",
    "                print(\"WRONG\")\n",
    "                right += 1\n",
    "            else: \n",
    "                print(\"WRONG\")\n",
    "                wrong += 1\n",
    "\n",
    "            tot += 1\n",
    "\n",
    "    right_ratio = right / tot * 100\n",
    "    print(f\"Test Accuracy: {right_ratio}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4772,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(784, [512, 512, 10], lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------------\n",
      "Loss: 2.304511\t [   64/59968]\n",
      "Loss: 2.276436\t [12864/59968]\n",
      "Loss: 2.272685\t [25664/59968]\n",
      "Loss: 2.214558\t [38464/59968]\n",
      "Loss: 2.182541\t [51264/59968]\n",
      "Test Accuracy: 33.37%\n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------------\n",
      "Loss: 2.155750\t [   64/59968]\n",
      "Loss: 2.176491\t [12864/59968]\n",
      "Loss: 2.175646\t [25664/59968]\n",
      "Loss: 2.121257\t [38464/59968]\n",
      "Loss: 2.100624\t [51264/59968]\n",
      "Test Accuracy: 55.24%\n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------------\n",
      "Loss: 2.111320\t [   64/59968]\n",
      "Loss: 2.105792\t [12864/59968]\n",
      "Loss: 2.103773\t [25664/59968]\n",
      "Loss: 2.101391\t [38464/59968]\n",
      "Loss: 2.080800\t [51264/59968]\n",
      "Test Accuracy: 62.71%\n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------------\n",
      "Loss: 2.092246\t [   64/59968]\n",
      "Loss: 2.075740\t [12864/59968]\n",
      "Loss: 2.090352\t [25664/59968]\n",
      "Loss: 2.095493\t [38464/59968]\n",
      "Loss: 2.073544\t [51264/59968]\n",
      "Test Accuracy: 66.58%\n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------------\n",
      "Loss: 2.073895\t [   64/59968]\n",
      "Loss: 2.057096\t [12864/59968]\n",
      "Loss: 2.079649\t [25664/59968]\n",
      "Loss: 2.090255\t [38464/59968]\n",
      "Loss: 2.051731\t [51264/59968]\n",
      "Test Accuracy: 69.22%\n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------------\n",
      "Loss: 2.075418\t [   64/59968]\n",
      "Loss: 2.050241\t [12864/59968]\n",
      "Loss: 2.070387\t [25664/59968]\n",
      "Loss: 2.109047\t [38464/59968]\n",
      "Loss: 2.069421\t [51264/59968]\n",
      "Test Accuracy: 70.66%\n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------------\n",
      "Loss: 2.052224\t [   64/59968]\n",
      "Loss: 2.031982\t [12864/59968]\n",
      "Loss: 2.071110\t [25664/59968]\n",
      "Loss: 2.075346\t [38464/59968]\n",
      "Loss: 2.062400\t [51264/59968]\n",
      "Test Accuracy: 71.88%\n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------------\n",
      "Loss: 2.065099\t [   64/59968]\n",
      "Loss: 2.032223\t [12864/59968]\n",
      "Loss: 2.073166\t [25664/59968]\n",
      "Loss: 2.091490\t [38464/59968]\n",
      "Loss: 2.047127\t [51264/59968]\n",
      "Test Accuracy: 72.16%\n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------------\n",
      "Loss: 2.052892\t [   64/59968]\n",
      "Loss: 2.035867\t [12864/59968]\n",
      "Loss: 2.068505\t [25664/59968]\n",
      "Loss: 2.060501\t [38464/59968]\n",
      "Loss: 2.059177\t [51264/59968]\n",
      "Test Accuracy: 74.04%\n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------------\n",
      "Loss: 2.040668\t [   64/59968]\n",
      "Loss: 2.029824\t [12864/59968]\n",
      "Loss: 2.070672\t [25664/59968]\n",
      "Loss: 2.074484\t [38464/59968]\n",
      "Loss: 2.060751\t [51264/59968]\n",
      "Test Accuracy: 74.20%\n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------------\n",
      "Loss: 2.047895\t [   64/59968]\n",
      "Loss: 2.035335\t [12864/59968]\n",
      "Loss: 2.060774\t [25664/59968]\n",
      "Loss: 2.067203\t [38464/59968]\n",
      "Loss: 2.026526\t [51264/59968]\n",
      "Test Accuracy: 75.00%\n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------------\n",
      "Loss: 2.039058\t [   64/59968]\n",
      "Loss: 2.022158\t [12864/59968]\n",
      "Loss: 2.065191\t [25664/59968]\n",
      "Loss: 2.075232\t [38464/59968]\n",
      "Loss: 2.034452\t [51264/59968]\n",
      "Test Accuracy: 74.98%\n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------------\n",
      "Loss: 2.032815\t [   64/59968]\n",
      "Loss: 2.029119\t [12864/59968]\n",
      "Loss: 2.061814\t [25664/59968]\n",
      "Loss: 2.060182\t [38464/59968]\n",
      "Loss: 2.035792\t [51264/59968]\n",
      "Test Accuracy: 75.24%\n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------------\n",
      "Loss: 2.039327\t [   64/59968]\n",
      "Loss: 2.022333\t [12864/59968]\n",
      "Loss: 2.068929\t [25664/59968]\n",
      "Loss: 2.048994\t [38464/59968]\n",
      "Loss: 2.032629\t [51264/59968]\n",
      "Test Accuracy: 75.97%\n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------------\n",
      "Loss: 2.042390\t [   64/59968]\n",
      "Loss: 2.026000\t [12864/59968]\n",
      "Loss: 2.067647\t [25664/59968]\n",
      "Loss: 2.052424\t [38464/59968]\n",
      "Loss: 2.047115\t [51264/59968]\n",
      "Test Accuracy: 76.23%\n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------------\n",
      "Loss: 2.024155\t [   64/59968]\n",
      "Loss: 2.026327\t [12864/59968]\n",
      "Loss: 2.070791\t [25664/59968]\n",
      "Loss: 2.048634\t [38464/59968]\n",
      "Loss: 2.025783\t [51264/59968]\n",
      "Test Accuracy: 76.33%\n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------------\n",
      "Loss: 2.025253\t [   64/59968]\n",
      "Loss: 2.019930\t [12864/59968]\n",
      "Loss: 2.060812\t [25664/59968]\n",
      "Loss: 2.052653\t [38464/59968]\n",
      "Loss: 2.021696\t [51264/59968]\n",
      "Test Accuracy: 76.64%\n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------------\n",
      "Loss: 2.032763\t [   64/59968]\n",
      "Loss: 2.013087\t [12864/59968]\n",
      "Loss: 2.062447\t [25664/59968]\n",
      "Loss: 2.044115\t [38464/59968]\n",
      "Loss: 2.050434\t [51264/59968]\n",
      "Test Accuracy: 76.79%\n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------------\n",
      "Loss: 2.033451\t [   64/59968]\n",
      "Loss: 2.012820\t [12864/59968]\n",
      "Loss: 2.049942\t [25664/59968]\n",
      "Loss: 2.050929\t [38464/59968]\n",
      "Loss: 2.047742\t [51264/59968]\n",
      "Test Accuracy: 77.42%\n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------------\n",
      "Loss: 2.037450\t [   64/59968]\n",
      "Loss: 2.018595\t [12864/59968]\n",
      "Loss: 2.052470\t [25664/59968]\n",
      "Loss: 2.046824\t [38464/59968]\n",
      "Loss: 2.045406\t [51264/59968]\n",
      "Test Accuracy: 77.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(20):\n",
    "    print(f\"Epoch {i + 1}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "        x_flattened = x.view(x.size(0), -1)\n",
    "\n",
    "        output = mlp(x_flattened)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        mlp.update_parameters()\n",
    "\n",
    "        if batch % 200 == 0:\n",
    "            print(f\"Loss: {loss:>7f}\\t [{((batch + 1) * 64):>5d}/{937 * 64}]\")\n",
    "\n",
    "    test(mlp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
