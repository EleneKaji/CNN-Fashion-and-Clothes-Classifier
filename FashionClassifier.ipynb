{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4785,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader # loads data either in chunks or full\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets # open datasets\n",
    "from torchvision.transforms import ToTensor # transfor data to tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 4786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing gpu for training\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training and test data from open datasets.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train_dataloader = DataLoader(train_data, batch_size=64) # goes over 938 batches of 64\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Shirt, Number: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting and understanding images and labels with first batch\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "idx = torch.randint(0, 64, (1,)).item()\n",
    "image = images[idx].squeeze()\n",
    "label = labels[idx]\n",
    "print(f\"Name: {labels_map[label.item()]}, Number: {label.item()}\")\n",
    "plt.imshow(image, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4790,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: \n",
    "    # nin is the number of input (prev layer)\n",
    "    # nout is the number of output (next layer)\n",
    "    def __init__(self, nin, nout, processor=\"cuda:0\"):\n",
    "        self.w = torch.randn((nin, nout), requires_grad=True, device=processor)\n",
    "        self.b = torch.randn(1, requires_grad=True, device=processor)\n",
    "    \n",
    "    # x is the input in (batch, input)\n",
    "    def __call__(self, x):\n",
    "        eq = torch.matmul(x, self.w) + self.b\n",
    "        out = torch.tanh(eq)\n",
    "        return out # returns (batch, output # of neurons for next layer)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts, lr, processor=\"cuda:0\"):\n",
    "        self.lr = lr\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters():\n",
    "                if param is not None:\n",
    "                    param -= param.grad * self.lr\n",
    "                    param.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mlp):\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    tot = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in test_dataloader:\n",
    "            test_x, test_y = test_x.to(\"cuda:0\"), test_y.to(\"cuda:0\")\n",
    "\n",
    "            test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "            output = mlp(test_x_flattened)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(test_y.view_as(pred)).sum().item()\n",
    "            tot += test_y.size(0)\n",
    "\n",
    "    accuracy = correct / tot * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4792,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mlp, loss_fn):\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "\n",
    "        x_flattened = x.view(x.size(0), -1)\n",
    "\n",
    "        output = mlp(x_flattened)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        mlp.update_parameters()\n",
    "\n",
    "        if batch % 200 == 0:\n",
    "            print(f\"Loss: {loss:>7f}\\t [{((batch + 1) * 64):>5d}/{937 * 64}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tune_hyperparameters():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_output(mlp):\n",
    "    tot = 0\n",
    "    wrong = 0\n",
    "    right = 0\n",
    "\n",
    "    for test_x, test_y in test_dataloader:\n",
    "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "\n",
    "        test_x_flattened = test_x.view(test_x.size(0), -1)\n",
    "\n",
    "        output = mlp(test_x_flattened)\n",
    "        \n",
    "        for pred, act, img in zip(output, test_y, test_x):\n",
    "            pred_index = torch.argmax(pred).item()\n",
    "            act_index = act.item()\n",
    "\n",
    "            print(f\"Predicted: {labels_map[pred_index]}, Number: {torch.max(output).item()}\")\n",
    "            print(f\"Target: {labels_map[act_index]}, Number: {act.item()}\")\n",
    "            img = img.cpu()\n",
    "            plt.imshow(img[0], cmap=\"grey\")\n",
    "            plt.show()\n",
    "\n",
    "            if pred_index == act_index:\n",
    "                print(\"WRONG\")\n",
    "                right += 1\n",
    "            else: \n",
    "                print(\"WRONG\")\n",
    "                wrong += 1\n",
    "\n",
    "            tot += 1\n",
    "\n",
    "    right_ratio = right / tot * 100\n",
    "    print(f\"Test Accuracy: {right_ratio}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4794,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(784, [512, 512, 10], lr=0.3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------------\n",
      "Loss: 2.298992\t [   64/59968]\n",
      "Loss: 2.293360\t [12864/59968]\n",
      "Loss: 2.266915\t [25664/59968]\n",
      "Loss: 2.234633\t [38464/59968]\n",
      "Loss: 2.223827\t [51264/59968]\n",
      "Test Accuracy: 38.68%\n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------------\n",
      "Loss: 2.199945\t [   64/59968]\n",
      "Loss: 2.174864\t [12864/59968]\n",
      "Loss: 2.174021\t [25664/59968]\n",
      "Loss: 2.147015\t [38464/59968]\n",
      "Loss: 2.140187\t [51264/59968]\n",
      "Test Accuracy: 56.46%\n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------------\n",
      "Loss: 2.139389\t [   64/59968]\n",
      "Loss: 2.103467\t [12864/59968]\n",
      "Loss: 2.118001\t [25664/59968]\n",
      "Loss: 2.093300\t [38464/59968]\n",
      "Loss: 2.091694\t [51264/59968]\n",
      "Test Accuracy: 63.09%\n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------------\n",
      "Loss: 2.131415\t [   64/59968]\n",
      "Loss: 2.071629\t [12864/59968]\n",
      "Loss: 2.095135\t [25664/59968]\n",
      "Loss: 2.070040\t [38464/59968]\n",
      "Loss: 2.083110\t [51264/59968]\n",
      "Test Accuracy: 67.14%\n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------------\n",
      "Loss: 2.102574\t [   64/59968]\n",
      "Loss: 2.062670\t [12864/59968]\n",
      "Loss: 2.075408\t [25664/59968]\n",
      "Loss: 2.077241\t [38464/59968]\n",
      "Loss: 2.088291\t [51264/59968]\n",
      "Test Accuracy: 68.69%\n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------------\n",
      "Loss: 2.082689\t [   64/59968]\n",
      "Loss: 2.057874\t [12864/59968]\n",
      "Loss: 2.072614\t [25664/59968]\n",
      "Loss: 2.089793\t [38464/59968]\n",
      "Loss: 2.088097\t [51264/59968]\n",
      "Test Accuracy: 70.62%\n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------------\n",
      "Loss: 2.069531\t [   64/59968]\n",
      "Loss: 2.066829\t [12864/59968]\n",
      "Loss: 2.075095\t [25664/59968]\n",
      "Loss: 2.074260\t [38464/59968]\n",
      "Loss: 2.077294\t [51264/59968]\n",
      "Test Accuracy: 71.97%\n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------------\n",
      "Loss: 2.056252\t [   64/59968]\n",
      "Loss: 2.042199\t [12864/59968]\n",
      "Loss: 2.069101\t [25664/59968]\n",
      "Loss: 2.066328\t [38464/59968]\n",
      "Loss: 2.071673\t [51264/59968]\n",
      "Test Accuracy: 71.88%\n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------------\n",
      "Loss: 2.045598\t [   64/59968]\n",
      "Loss: 2.050179\t [12864/59968]\n",
      "Loss: 2.060525\t [25664/59968]\n",
      "Loss: 2.068279\t [38464/59968]\n",
      "Loss: 2.071680\t [51264/59968]\n",
      "Test Accuracy: 73.31%\n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------------\n",
      "Loss: 2.044173\t [   64/59968]\n",
      "Loss: 2.042336\t [12864/59968]\n",
      "Loss: 2.045791\t [25664/59968]\n",
      "Loss: 2.064134\t [38464/59968]\n",
      "Loss: 2.057100\t [51264/59968]\n",
      "Test Accuracy: 73.84%\n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------------\n",
      "Loss: 2.076153\t [   64/59968]\n",
      "Loss: 2.031882\t [12864/59968]\n",
      "Loss: 2.066559\t [25664/59968]\n",
      "Loss: 2.054918\t [38464/59968]\n",
      "Loss: 2.061165\t [51264/59968]\n",
      "Test Accuracy: 75.02%\n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------------\n",
      "Loss: 2.058600\t [   64/59968]\n",
      "Loss: 2.025572\t [12864/59968]\n",
      "Loss: 2.051133\t [25664/59968]\n",
      "Loss: 2.060236\t [38464/59968]\n",
      "Loss: 2.053185\t [51264/59968]\n",
      "Test Accuracy: 75.13%\n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------------\n",
      "Loss: 2.050909\t [   64/59968]\n",
      "Loss: 2.023914\t [12864/59968]\n",
      "Loss: 2.055177\t [25664/59968]\n",
      "Loss: 2.060427\t [38464/59968]\n",
      "Loss: 2.045518\t [51264/59968]\n",
      "Test Accuracy: 76.13%\n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------------\n",
      "Loss: 2.048682\t [   64/59968]\n",
      "Loss: 2.020510\t [12864/59968]\n",
      "Loss: 2.052432\t [25664/59968]\n",
      "Loss: 2.049352\t [38464/59968]\n",
      "Loss: 2.055282\t [51264/59968]\n",
      "Test Accuracy: 76.39%\n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------------\n",
      "Loss: 2.030094\t [   64/59968]\n",
      "Loss: 2.020525\t [12864/59968]\n",
      "Loss: 2.058653\t [25664/59968]\n",
      "Loss: 2.051236\t [38464/59968]\n",
      "Loss: 2.055297\t [51264/59968]\n",
      "Test Accuracy: 77.16%\n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------------\n",
      "Loss: 2.033267\t [   64/59968]\n",
      "Loss: 2.020885\t [12864/59968]\n",
      "Loss: 2.048848\t [25664/59968]\n",
      "Loss: 2.044106\t [38464/59968]\n",
      "Loss: 2.066191\t [51264/59968]\n",
      "Test Accuracy: 76.39%\n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------------\n",
      "Loss: 2.032533\t [   64/59968]\n",
      "Loss: 2.019317\t [12864/59968]\n",
      "Loss: 2.047221\t [25664/59968]\n",
      "Loss: 2.050004\t [38464/59968]\n",
      "Loss: 2.057464\t [51264/59968]\n",
      "Test Accuracy: 77.20%\n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------------\n",
      "Loss: 2.041082\t [   64/59968]\n",
      "Loss: 2.019038\t [12864/59968]\n",
      "Loss: 2.046819\t [25664/59968]\n",
      "Loss: 2.042654\t [38464/59968]\n",
      "Loss: 2.059245\t [51264/59968]\n",
      "Test Accuracy: 77.14%\n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------------\n",
      "Loss: 2.050850\t [   64/59968]\n",
      "Loss: 2.017525\t [12864/59968]\n",
      "Loss: 2.042466\t [25664/59968]\n",
      "Loss: 2.046814\t [38464/59968]\n",
      "Loss: 2.053559\t [51264/59968]\n",
      "Test Accuracy: 78.02%\n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------------\n",
      "Loss: 2.027733\t [   64/59968]\n",
      "Loss: 2.004226\t [12864/59968]\n",
      "Loss: 2.034409\t [25664/59968]\n",
      "Loss: 2.048960\t [38464/59968]\n",
      "Loss: 2.056170\t [51264/59968]\n",
      "Test Accuracy: 78.09%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"Epoch {i + 1}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    train(mlp, loss_fn)\n",
    "    test(mlp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
